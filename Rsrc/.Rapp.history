rm rexpokit/src/*.o; rm rexpokit/src/*.so; rm rexpokit/src/lapack/*.o
library(rexpokit)
checkVersion(rexpokit)
packageVersion("rexpokit")
?rexpokit
Qmat = matrix(c(-1.218, 0.504, 0.336, 0.378, 0.126, -0.882, 0.252, 0.504,#
0.168, 0.504, -1.05, 0.378, 0.126, 0.672, 0.252, -1.05), nrow=4, byrow=TRUE)#
#
# Make a series of t values#
tvals = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 14)#
#
# Exponentiate each with EXPOKIT's dgpadm (good for small dense matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dgpadm_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# Exponentiate each with EXPOKIT's dmexpv (should be fast for large sparse matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dmexpv_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=2)#
#
# DGEXPV, single t-value#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=2)#
#
# These functions runs the for-loop itself (sadly, we could not get mapply() to work#
# on a function that calls dmexpv/dgexpv), returning a list of probability matrices.#
#
# DMEXPV functions#
list_of_P_matrices_dmexpv = expokit_wrapalldmexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dmexpv#
#
# DGEXPV functions#
list_of_P_matrices_dgexpv = expokit_wrapalldgexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dgexpv#
#
# Check if there are differences in the results (might only happen for large problems)#
cat("\n")#
cat("Differences between dmexpv and dgexpv\n")#
#
for (i in 1:length(list_of_P_matrices_dmexpv))#
	{#
	diffs = list_of_P_matrices_dmexpv[[i]] - list_of_P_matrices_dgexpv[[i]]#
	print(diffs)#
	cat("\n")#
	}
library(rexpokit)
?rexpokit
library(rexpokit)#
#
# Make a square instantaneous rate matrix (Q matrix)#
# This matrix is taken from Peter Foster's (2001) "The Idiot's Guide#
# to the Zen of Likelihood in a Nutshell in Seven Days for Dummies,#
# Unleashed" at:#
# \url{http://www.bioinf.org/molsys/data/idiots.pdf}#
##
# The Q matrix includes the stationary base freqencies, which Pmat#
# converges to as t becomes large.#
Qmat = matrix(c(-1.218, 0.504, 0.336, 0.378, 0.126, -0.882, 0.252, 0.504,#
0.168, 0.504, -1.05, 0.378, 0.126, 0.672, 0.252, -1.05), nrow=4, byrow=TRUE)#
#
# Make a series of t values#
tvals = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 14)#
#
# Exponentiate each with EXPOKIT's dgpadm (good for small dense matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dgpadm_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# Exponentiate each with EXPOKIT's dmexpv (should be fast for large sparse matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dmexpv_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# DMEXPV and DGEXPV are designed for large, sparse Q matrices (sparse = lots of zeros).#
# DMEXPV is specifically designed for Markov chains and so may be slower, but more accurate.#
#
# DMEXPV, single t-value#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=2)#
#
# DGEXPV, single t-value#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=2)#
#
# These functions runs the for-loop itself (sadly, we could not get mapply() to work#
# on a function that calls dmexpv/dgexpv), returning a list of probability matrices.#
#
# DMEXPV functions#
list_of_P_matrices_dmexpv = expokit_wrapalldmexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dmexpv#
#
# DGEXPV functions#
list_of_P_matrices_dgexpv = expokit_wrapalldgexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dgexpv#
#
# Check if there are differences in the results (might only happen for large problems)#
cat("\n")#
cat("Differences between dmexpv and dgexpv\n")#
#
for (i in 1:length(list_of_P_matrices_dmexpv))#
	{#
	diffs = list_of_P_matrices_dmexpv[[i]] - list_of_P_matrices_dgexpv[[i]]#
	print(diffs)#
	cat("\n")#
	}
library(devtools)
install_github("danlwarren/ENMTools")
library(ENMTools)
packageVersion(ENMTools)
packageVersion("ENMTools")
library(BioGeoBEARS)
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
	# Produces stop error#
	get_dmat_times_from_BioGeoBEARS_run_object(BioGeoBEARS_run_object, BioGeoBEARS_model_object=NULL, numstates=NULL, max_range_size=NULL)#
	# Works:#
	# Get the dmat (trivial case, non-stratified Psychotria example)#
	get_dmat_times_from_BioGeoBEARS_run_object(BioGeoBEARS_run_object, numstates=NULL, max_range_size=4)
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
	# Get the dmat (trivial case, non-stratified Psychotria example)#
	tmpres = get_dmat_times_from_BioGeoBEARS_run_object(BioGeoBEARS_run_object, numstates=NULL, max_range_size=4)#
	tmpres
is_list_not_dataframe <- function(obj)#
	{#
	setup='#
	# Set up a BioGeoBEARS_run_object#
	BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
	# Get the dmat (trivial case, non-stratified Psychotria example)#
	tmpres = get_dmat_times_from_BioGeoBEARS_run_object(BioGeoBEARS_run_object, numstates=NULL, max_range_size=4)#
	tmpres#
	is_list_not_dataframe(obj=tmpres$dmat)#
	'#
	TF1 = is.list(obj)#
	TF2 = (class(obj) == "data.frame") == FALSE#
	TF = (TF1 + TF2) == 2#
	return(TF)#
	}
is_list_not_dataframe(obj=tmpres$dmat)
is.list(tmpres$dmat)
class(tmpres$dmat)
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
	# Get the dmat (trivial case, non-stratified Psychotria example)#
	tmpres = get_dmat_times_from_BioGeoBEARS_run_object(BioGeoBEARS_run_object, numstates=NULL, max_range_size=4)#
	tmpres#
	class(tmpres)#
	length(tmpres)#
	tmpdf = as.data.frame(tmpres)#
	tmpdf#
	class(tmpdf)#
	length(tmpdf)#
	is.list(tmpres$dmat)#
	is_list_not_dataframe(obj=tmpres$dmat)#
#
	is.list(tmpdf)#
	is_list_not_dataframe(obj=tmpdf)
source('/GitHub/BioGeoBEARS/R/aa_generics_v1.R', chdir = TRUE)
source('/GitHub/BioGeoBEARS/R/summarize_BSM_tables_v1.R', chdir = TRUE)
BSMs_w_sourceAreas = simulate_source_areas_ana_clado(res, clado_events_tables, ana_events_tables, areanames)
res
library(BioGeoBEARS)
trfn = "~/Downloads/Smilisca_tree.newick"
tr = read.tree(trfn)
library(ape)
tr = read.tree(trfn)
tr
plot(tr)
axisPhylo()
library(ape)
newick_str = "(((Humans, Chimps), Gorillas), Orangs);"
tr = read.tree(text=newick_str)
tr
class(tr)
names(tr)
tr$edge
tr$Nnode
tr$tip.label
plot(tr)
tiplabels(tr)
edgelabels(tr)
plot(tr)
edgelabels(tr)
edgelabels(tr, edge=1:7)
library(BioGeoBEARS)
prt(tr)
prt(tr, printflag=FALSE)
plot(tr)
ntips = length(tr$tip.label)#
Rnodenums = (ntips+1):(ntips+tr$Nnode)#
tipnums = 1:ntips
tiplabels(cex=1.5)#
nodelabels(text=Rnodenums, node=Rnodenums, cex=1.5)
newick_str
tr2 = drop.tip(phy=tr, tip=c("Chimps","Gorillas"))
tr2
plot(tr2)
write.tree(phy=tr2, file="")
list_of_names_containing_i_TF = grepl(pattern="i", x=tr$tip.label)
list_of_names_containing_i_TF
tiplabels_to_drop = tr$tip.label[list_of_names_containing_i_TF]
tiplabels_to_drop
tr2 = drop.tip(phy=tr, tip= tiplabels_to_drop)
tr2
trtable = prt(tr)
trtable
trtable = prt(tr, get_tipnames=TRUE)
trtable
library(BioGeoBEARS)
add_per_area_probs_to_corners()
corner_coords()
np(system.file("extdata", package="BioGeoBEARS"))
normalizePath(system.file("extdata", package="BioGeoBEARS"))
slashslash(addslash(np(system.file("extdata", package="BioGeoBEARS"))), "a_scripts/")
slashslash(paste0(addslash(np(system.file("extdata", package="BioGeoBEARS"))), "a_scripts/"))
paste0(addslash(np(system.file("extdata", package="BioGeoBEARS"))), "a_scripts/"
)
?paste0(addslash(np(system.file("extdata", package="BioGeoBEARS"))), "a_scripts/"
slashslash
slashslash(paste0(addslash(np(system.file("extdata", package="BioGeoBEARS"))), "a_scripts/"))
paste(extdata_dir, "a_scripts" , sep="/")
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
	tmplocation=paste(extdata_dir, "a_scripts" , sep="/")
tmplocation
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
	tmplocation=slashslash(paste(extdata_dir, "a_scripts" , sep="/"))
# Load the package (after installation, see above).#
library(GenSA)    # GenSA is better than optimx (although somewhat slower)#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
#
########################################################
# 2018-10-10 update: I have been putting the #
# updates on CRAN/GitHub#
# You should use:#
# rexpokit version 0.26.6 from CRAN#
# cladoRcpp version 0.15 from CRAN#
# BioGeoBEARS version 1.1 from GitHub, install with:#
# library(devtools)#
# devtools::install_github(repo="nmatzke/BioGeoBEARS")#
########################################################
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)
sourceall("/drives/Dropbox/_njm/__packages/BioGeoBEARS_setup/")
# Load the package (after installation, see above).#
library(GenSA)    # GenSA is better than optimx (although somewhat slower)#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
#
########################################################
# 2018-10-10 update: I have been putting the #
# updates on CRAN/GitHub#
# You should use:#
# rexpokit version 0.26.6 from CRAN#
# cladoRcpp version 0.15 from CRAN#
# BioGeoBEARS version 1.1 from GitHub, install with:#
# library(devtools)#
# devtools::install_github(repo="nmatzke/BioGeoBEARS")#
########################################################
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)
ll("/GitHub/BioGeoBEARS/R")
sourceAll("/GitHub/BioGeoBEARS/R")
sourceall("/GitHub/BioGeoBEARS/R")
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
	tmplocation = slashslash(paste(extdata_dir, "a_scripts" , sep="/"))
if (tmplocation == "manual")#
		{#
		scriptdir = "/Dropbox/_njm/__packages/BioGeoBEARS_setup/inst/extdata/a_scripts/"#
		} else if (tmplocation == "auto") {#
		extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
		scriptdir = slashslash(paste(extdata_dir, "a_scripts" , sep="/"))#
		} else {#
		{#
		scriptdir = tmplocation#
		}
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
		scriptdir = slashslash(paste(extdata_dir, "a_scripts" , sep="/"))
sourceall("/GitHub/BioGeoBEARS/R")
wd = np("~")#
setwd(wd)#
#
# Double-check your working directory with getwd()#
getwd()#
#
########################################################
# SETUP: Extension data directory#
########################################################
# When R packages contain extra files, they are stored in the "extdata" directory #
# inside the installed package.#
##
# BioGeoBEARS contains various example files and scripts in its extdata directory.#
# #
# Each computer operating system might install BioGeoBEARS in a different place, #
# depending on your OS and settings. #
# #
# However, you can find the extdata directory like this:#
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny (plots to a PDF, which avoids issues with multiple graphics in same window):#
pdffn = "tree.pdf"#
pdf(file=pdffn, width=9, height=12)#
#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)#
#
########################################################
# Geography file#
# Notes:#
# 1. This is a PHYLIP-formatted file. This means that in the #
#    first line, #
#    - the 1st number equals the number of rows (species)#
#    - the 2nd number equals the number of columns (number of areas)#
#    - after a tab, put the areas in parentheses, with spaces: (A B C D)#
##
# 1.5. Example first line:#
#    10    4    (A B C D)#
# #
# 2. The second line, and subsequent lines:#
#    speciesA    0110#
#    speciesB    0111#
#    speciesC    0001#
#         ...#
# #
# 2.5a. This means a TAB between the species name and the area 0/1s#
# 2.5b. This also means NO SPACE AND NO TAB between the area 0/1s.#
# #
# 3. See example files at:#
#    http://phylo.wikidot.com/biogeobears#files#
# #
# 4. Make you understand what a PLAIN-TEXT EDITOR is:#
#    http://phylo.wikidot.com/biogeobears#texteditors#
##
# 3. The PHYLIP format is the same format used for C++ LAGRANGE geography files.#
##
# 4. All names in the geography file must match names in the phylogeny file.#
##
# 5. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
##
# 6. Operational taxonomic units (OTUs) should ideally be phylogenetic lineages, #
#    i.e. genetically isolated populations.  These may or may not be identical #
#    with species.  You would NOT want to just use specimens, as each specimen #
#    automatically can only live in 1 area, which will typically favor DEC+J #
#    models.  This is fine if the species/lineages really do live in single areas,#
#    but you wouldn't want to assume this without thinking about it at least. #
#    In summary, you should collapse multiple specimens into species/lineages if #
#    data indicates they are the same genetic population.#
#######################################################
#
# This is the example geography file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))#
#
# Look at the raw geography text file:#
moref(geogfn)#
#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Set the maximum number of areas any species may occupy; this cannot be larger #
# than the number of areas you set up, but it can be smaller.#
max_range_size = 4#
#
#####################################################
#####################################################
# KEY HINT: The number of states (= number of different possible geographic ranges)#
# depends on (a) the number of areas and (b) max_range_size.#
# If you have more than about 500-600 states, the calculations will get REALLY slow,#
# since the program has to exponentiate a matrix of e.g. 600x600.  Often the computer#
# will just sit there and crunch, and never get through the calculation of the first#
# likelihood.#
# #
# (this is also what is usually happening when LAGRANGE hangs: you have too many states!)#
##
# To check the number of states for a given number of ranges, try:#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=FALSE)#
numstates_from_numareas(numareas=4, maxareas=3, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=2, include_null_range=TRUE)#
#
# Large numbers of areas have problems:#
numstates_from_numareas(numareas=10, maxareas=10, include_null_range=TRUE)#
#
# ...unless you limit the max_range_size:#
numstates_from_numareas(numareas=10, maxareas=2, include_null_range=TRUE)#
#####################################################
#####################################################
#
########################################################
########################################################
# DEC AND DEC+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DEC" model is identical with #
# the Lagrange DEC model, and should return identical#
# ML estimates of parameters, and the same #
# log-likelihoods, for the same datasets.#
##
# Ancestral state probabilities at nodes will be slightly #
# different, since BioGeoBEARS is reporting the #
# ancestral state probabilities under the global ML#
# model, and Lagrange is reporting ancestral state#
# probabilities after re-optimizing the likelihood#
# after fixing the state at each node. These will #
# be similar, but not identical. See Matzke (2014),#
# Systematic Biology, for discussion.#
##
# Also see Matzke (2014) for presentation of the #
# DEC+J model.#
########################################################
########################################################
#
########################################################
########################################################
#
########################################################
# Run DEC#
########################################################
#
# Intitialize a default model (DEC model)#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
# Give BioGeoBEARS the location of the phylogeny Newick file#
BioGeoBEARS_run_object$trfn = trfn#
#
# Give BioGeoBEARS the location of the geography text file#
BioGeoBEARS_run_object$geogfn = geogfn#
#
# Input the maximum range size#
BioGeoBEARS_run_object$max_range_size = max_range_size#
#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
# 1. Here, un-comment ONLY the files you want to use.#
# 2. Also un-comment "BioGeoBEARS_run_object = section_the_tree(...", below.#
# 3. For example files see (a) extdata_dir, #
#  or (b) http://phylo.wikidot.com/biogeobears#files#
#  and BioGeoBEARS Google Group posts for further hints)#
##
# Uncomment files you wish to use in time-stratified analyses:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
# (use more cores to speed it up; this requires#
# library(parallel) and/or library(snow). The package "parallel" #
# is now default on Macs in R 3.0+, but apparently still #
# has to be typed on some Windows machines. Note: apparently #
# parallel works on Mac command-line R, but not R.app.#
# BioGeoBEARS checks for this and resets to 1#
# core with R.app)#
#
# Sparse matrix exponentiation is an option for huge numbers of ranges/states (600+)#
# I have experimented with sparse matrix exponentiation in EXPOKIT/rexpokit,#
# but the results are imprecise and so I haven't explored it further.#
# In a Bayesian analysis, it might work OK, but the ML point estimates are#
# not identical.#
# Also, I have not implemented all functions to work with force_sparse=TRUE.#
# Volunteers are welcome to work on it!!#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC model#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
# Run this to check inputs. Read the error messages if you get them!#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = TRUE#
resfn = "Psychotria_DEC_M0_unconstrained_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDEC = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDEC = res#
    }#
#
########################################################
# Run DEC+J#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC+J model#
# Get the ML parameter values from the 2-parameter nested model#
# (this will ensure that the 3-parameter model always does at least as good)#
dstart = resDEC$outputs@params_table["d","est"]#
estart = resDEC$outputs@params_table["e","est"]#
jstart = 0.0001#
#
# Input starting values for d, e#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = estart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = estart#
#
# Add j as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
resfn = "Psychotria_DEC+J_M0_unconstrained_v1.Rdata"#
runslow = TRUE#
if (runslow)#
    {#
    #sourceall("/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
#
    resDECj = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDECj = res#
    }#
#
########################################################
# PDF plots#
########################################################
pdffn = "Psychotria_DEC_vs_DEC+J_M0_unconstrained_v1.pdf"#
pdf(pdffn, width=6, height=6)#
#
########################################################
# Plot ancestral states - DEC#
########################################################
analysis_titletxt ="BioGeoBEARS DEC on Psychotria M0_unconstrained"#
#
# Setup#
results_object = resDEC#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res2 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
########################################################
# Plot ancestral states - DECJ#
########################################################
analysis_titletxt ="BioGeoBEARS DEC+J on Psychotria M0_unconstrained"#
#
# Setup#
results_object = resDECj#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
dev.off()  # Turn off PDF#
cmdstr = paste("open ", pdffn, sep="")#
system(cmdstr) # Plot it
library(XLConnect)
tlibrary(ape0)
library(ape)
trfn = "/drives/GDrive/z_help/Orlando/biogeobearsquestions/tree.newick"
tr = read.tree(trfn)
min(tr$edge.length)
is.binary(tr)
prt(tr)
library(BioGeoBEARS)
prt(tr)
trtable =prt(tr)
trtable$time_bp
hist(time_bp)
hist(trtable$time_bp)
library(ape)
trstr="((olivacea:0.827,fusca:0.827):0.074,(Platyspiza:0.546,(Pinaroloxias:0.529,(difficilis:0.469,(((pauper:0.174,psittacula:0.174):0.031,(parvulus:0.204,pallida:0.204):0.001):0.207,((fuliginosa:0.25,fortis:0.25):0.008,(scandens:0.236,(magnirostris:0.17,conirostris:0.17):0.066):0.022):0.154):0.057):0.06):0.017):0.355);"
tr=read.tree(trstr)
tr=read.tree(trstr, file="")
tr
plot(tr)
axisPhylo()
install.packages("vtable")
library(vtable)
?vtable
if(interactive()){#
df <- data.frame(var1 = 1:4,var2=5:8,var3=c('A','B','C','D'),#
    var4=as.factor(c('A','B','C','C')),var5=c(TRUE,TRUE,FALSE,FALSE))
#Demonstrating different options:#
vtable(df,labels=c('Number 1','Number 2','Some Letters',#
    'Some Labels','You Good?'))#
vtable(subset(df,select=c(1,2,5)),#
    labels=c('Number 1','Number 2','You Good?'),class=FALSE,values=FALSE)#
vtable(subset(df,select=c('var1','var4')),#
    labels=c('Number 1','Some Labels'),#
    factor.limit=1,col.width=c(10,10,40,35))#
#
#Different methods of applying variable labels:#
labelsmethod2 <- data.frame(var1='Number 1',var2='Number 2',#
    var3='Some Letters',var4='Some Labels',var5='You Good?')#
vtable(df,labels=labelsmethod2)#
labelsmethod3 <- data.frame(a =c("var1","var2","var3","var4","var5"),#
    b=c('Number 1','Number 2','Some Letters','Some Labels','You Good?'))#
vtable(df,labels=labelsmethod3)#
#
#Using value labels and pre-labeled data:#
library(sjlabelled)#
df <- set_label(df,c('Number 1','Number 2','Some Letters',#
    'Some Labels','You Good?'))#
df$var1 <- set_labels(df$var1,labels=c('A little','Some more',#
'Even more','A lot'))#
vtable(df)#
#
#efc is data with embedded variable and value labels from the sjlabelled package#
library(sjlabelled)#
data(efc)#
vtable(efc)#
#
#Displaying the values of a character vector#
data(USJudgeRatings)#
USJudgeRatings$Judge <- row.names(USJudgeRatings)#
vtable(USJudgeRatings,char.values=c('Judge'))#
#
#Adding summary statistics for variable mean and proportion of data that is missing.#
vtable(efc,summ=c('mean(x)','propNA(x)'))#
#
}
library(ape)
reorder.phylo
.reorder_ape
phylo.reorder_ape
ape:::.reorder_ape
library(BioGeoBEARS)
great_ape_newick_string = "(((human:6,(chimp1:0.5,bonobo:0.5):5.5):1,gorilla:7):5,orangutan:12);"
tr = read.tree(file="", great_ape_newick_string)
tr
prt(tr)
tr2=reorder(tr,"pruningwise")
prt(tr,FALSE)
prt(tr2,FALSE)
tr$edge
tr2$edge
tr2
downpass_edgematrix
~/Downloads/rspb20090876supp4.txt
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
cat(tr$tip.label, sep="\n")
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
cat(tr$tip.label, sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Calotomus",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
cat(tr$tip.label, sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Calotomus",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = grepl(pattern=original_txt, replacement=new_txt, x=newick_str_orig)#
newick_str_new
grepl()
newick_str_new = gsub(pattern=original_txt, replacement=new_txt, x=newick_str_orig)#
newick_str_new
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Calotomus",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = gsub(pattern=original_txt, replacement=new_txt, x=newick_str_orig)#
newick_str_new#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Calotomus",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_orig)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")
?drop.tip()
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Calotomus",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_orig)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")#
# Keep the tips Kendall emailed#
#
species_to_keep = c("Bolobometopon_muricatum",#
"Calotomus_carolinus",#
"Calotomus_spinidens",#
"Cetoscarus_bicolor",#
"Chlorurus_bleekeri",#
"Chlorurus_frontalis",#
"Chlorurus_microrhinos",#
"Chlorurus_sordidus",#
"Hipposcarus_longiceps",#
"Leptoscarus_vaigiensis",#
"Scarus_altipinnis",#
"Scarus_chameleon",#
"Scarus_dimidiatus",#
"Scarus_flavipectoralis",#
"Scarus_forsteni",#
"Scarus_frenatus",#
"Scarus_ghobban",#
"Scarus_globiceps",#
"Scarus_niger",#
"Scarus_oviceps",#
"Scarus_psittacus",#
"Scarus_quoyi",#
"Scarus_rivulatus",#
"Scarus_rubroviolaceus",#
"Scarus_schlegeli",#
"Scarus_spinus")#
#
tr3 = keep.tip(phy=tr2, tip=species_to_keep)#
#
length(species_to_keep)#
length(tr3$tip.label)
cat(sort(tr$tip.label), sep="\n")
cat(sort(tr2$tip.label), sep="\n")
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Calotomus",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_new)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")#
# Keep the tips Kendall emailed#
#
species_to_keep = c("Bolobometopon_muricatum",#
"Calotomus_carolinus",#
"Calotomus_spinidens",#
"Cetoscarus_bicolor",#
"Chlorurus_bleekeri",#
"Chlorurus_frontalis",#
"Chlorurus_microrhinos",#
"Chlorurus_sordidus",#
"Hipposcarus_longiceps",#
"Leptoscarus_vaigiensis",#
"Scarus_altipinnis",#
"Scarus_chameleon",#
"Scarus_dimidiatus",#
"Scarus_flavipectoralis",#
"Scarus_forsteni",#
"Scarus_frenatus",#
"Scarus_ghobban",#
"Scarus_globiceps",#
"Scarus_niger",#
"Scarus_oviceps",#
"Scarus_psittacus",#
"Scarus_quoyi",#
"Scarus_rivulatus",#
"Scarus_rubroviolaceus",#
"Scarus_schlegeli",#
"Scarus_spinus")#
#
tr3 = keep.tip(phy=tr2, tip=species_to_keep)#
#
length(species_to_keep)#
length(tr3$tip.label)
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_new)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")#
# Keep the tips Kendall emailed#
#
species_to_keep = c("Bolobometopon_muricatum",#
"Calotomus_carolinus",#
"Calotomus_spinidens",#
"Cetoscarus_bicolor",#
"Chlorurus_bleekeri",#
"Chlorurus_frontalis",#
"Chlorurus_microrhinos",#
"Chlorurus_sordidus",#
"Hipposcarus_longiceps",#
"Leptoscarus_vaigiensis",#
"Scarus_altipinnis",#
"Scarus_chameleon",#
"Scarus_dimidiatus",#
"Scarus_flavipectoralis",#
"Scarus_forsteni",#
"Scarus_frenatus",#
"Scarus_ghobban",#
"Scarus_globiceps",#
"Scarus_niger",#
"Scarus_oviceps",#
"Scarus_psittacus",#
"Scarus_quoyi",#
"Scarus_rivulatus",#
"Scarus_rubroviolaceus",#
"Scarus_schlegeli",#
"Scarus_spinus")#
#
tr3 = keep.tip(phy=tr2, tip=species_to_keep)#
#
length(species_to_keep)#
length(tr3$tip.label)
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Bolbometopon",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_new)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")#
# Keep the tips Kendall emailed#
#
species_to_keep = c("Bolobometopon_muricatum",#
"Calotomus_carolinus",#
"Calotomus_spinidens",#
"Cetoscarus_bicolor",#
"Chlorurus_bleekeri",#
"Chlorurus_frontalis",#
"Chlorurus_microrhinos",#
"Chlorurus_sordidus",#
"Hipposcarus_longiceps",#
"Leptoscarus_vaigiensis",#
"Scarus_altipinnis",#
"Scarus_chameleon",#
"Scarus_dimidiatus",#
"Scarus_flavipectoralis",#
"Scarus_forsteni",#
"Scarus_frenatus",#
"Scarus_ghobban",#
"Scarus_globiceps",#
"Scarus_niger",#
"Scarus_oviceps",#
"Scarus_psittacus",#
"Scarus_quoyi",#
"Scarus_rivulatus",#
"Scarus_rubroviolaceus",#
"Scarus_schlegeli",#
"Scarus_spinus")#
#
tr3 = keep.tip(phy=tr2, tip=species_to_keep)
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Bolbometopon",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_new)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")#
# Keep the tips Kendall emailed#
#
species_to_keep = c("Bolobometopon_muricatum",#
"Calotomus_carolinus",#
"Calotomus_spinidens",#
"Cetoscarus_bicolor",#
"Chlorurus_bleekeri",#
#"Chlorurus_frontalis",#
"Chlorurus_microrhinos",#
"Chlorurus_sordidus",#
"Hipposcarus_longiceps",#
"Leptoscarus_vaigiensis",#
"Scarus_altipinnis",#
"Scarus_chameleon",#
"Scarus_dimidiatus",#
"Scarus_flavipectoralis",#
"Scarus_forsteni",#
"Scarus_frenatus",#
"Scarus_ghobban",#
"Scarus_globiceps",#
"Scarus_niger",#
"Scarus_oviceps",#
"Scarus_psittacus",#
"Scarus_quoyi",#
"Scarus_rivulatus",#
"Scarus_rubroviolaceus",#
"Scarus_schlegeli",#
"Scarus_spinus")#
#
tr3 = keep.tip(phy=tr2, tip=species_to_keep)#
#
length(species_to_keep)#
length(tr3$tip.label)
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Bolbometopon",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_new)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")#
# Keep the tips Kendall emailed#
#
species_to_keep = c("Bolbometopon_muricatum",#
#"Bolobometopon_muricatum",#
"Calotomus_carolinus",#
"Calotomus_spinidens",#
"Cetoscarus_bicolor",#
"Chlorurus_bleekeri",#
#"Chlorurus_frontalis",#
"Chlorurus_microrhinos",#
"Chlorurus_sordidus",#
"Hipposcarus_longiceps",#
"Leptoscarus_vaigiensis",#
"Scarus_altipinnis",#
"Scarus_chameleon",#
"Scarus_dimidiatus",#
"Scarus_flavipectoralis",#
"Scarus_forsteni",#
"Scarus_frenatus",#
"Scarus_ghobban",#
"Scarus_globiceps",#
"Scarus_niger",#
"Scarus_oviceps",#
"Scarus_psittacus",#
"Scarus_quoyi",#
"Scarus_rivulatus",#
"Scarus_rubroviolaceus",#
"Scarus_schlegeli",#
"Scarus_spinus")#
#
tr3 = keep.tip(phy=tr2, tip=species_to_keep)#
#
length(species_to_keep)#
length(tr3$tip.label)
library(ape)#
#
trfn = "~/Downloads/rspb20090876supp4.txt"#
tr = read.tree(trfn)#
#
# Look at names#
cat(sort(tr$tip.label), sep="\n")#
#
# Fix the names (they are missing the space/underscore between genus/species)#
original_txt = c("Bolobometopon",#
"Bolbometopon",#
"Calotomus",#
"Cetoscarus",#
"Chlorurus",#
"Hipposcarus",#
"Leptoscarus",#
"Scarus")#
#
new_txt = paste0(original_txt, "_")#
new_txt#
#
newick_str_orig = write.tree(tr, file="")#
newick_str_new = newick_str_orig#
for (i in 1:length(new_txt))#
	{#
	newick_str_new = gsub(pattern=original_txt[i], replacement=new_txt[i], x=newick_str_new)#
	newick_str_new#
	}#
#
tr2 = read.tree(file="", text=newick_str_new)#
cat(sort(tr2$tip.label), sep="\n")#
# Keep the tips Kendall emailed#
#
species_to_keep = c("Bolbometopon_muricatum",#
#"Bolobometopon_muricatum",#
"Calotomus_carolinus",#
"Calotomus_spinidens",#
"Cetoscarus_bicolor",#
"Chlorurus_bleekeri",#
#"Chlorurus_frontalis",#
"Chlorurus_microrhinos",#
"Chlorurus_sordidus",#
"Hipposcarus_longiceps",#
"Leptoscarus_vaigiensis",#
"Scarus_altipinnis",#
"Scarus_chameleon",#
"Scarus_dimidiatus",#
"Scarus_flavipectoralis",#
"Scarus_forsteni",#
"Scarus_frenatus",#
"Scarus_ghobban",#
"Scarus_globiceps",#
"Scarus_niger",#
"Scarus_oviceps",#
"Scarus_psittacus",#
"Scarus_quoyi",#
"Scarus_rivulatus",#
"Scarus_rubroviolaceus",#
"Scarus_schlegeli",#
"Scarus_spinus")#
#
tr3 = keep.tip(phy=tr2, tip=species_to_keep)#
#
length(species_to_keep)#
length(tr3$tip.label)#
#
write.tree(tr3, file="rspb20090876supp4_25species.newick")#
#
pdffn = "rspb20090876supp4_25species.pdf"#
pdf(file=pdffn, width=8, height=12)#
#
plot(tr3)#
title("rspb20090876supp4_25species.txt, subset to 25 sp.")#
axisPhylo()#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)
library(sdm)
install.packages("sdm")
library(sdm)
vignettes(sdm)
vignette(sdm)
vignette("sdm")
?sdm
## Not run: #
file <- system.file("external/pa_df.csv", package="sdm")#
#
df <- read.csv(file)#
#
head(df) #
#
d <- sdmData(sp~b15+NDVI,train=df)#
#
d
#----#
# Example 1: fit using 3 models, and no evaluation (evaluation based on training dataset):#
#
m <- sdm(sp~b15+NDVI,data=d,methods=c('glm','gam','gbm'))#
#
m#
#
# Example 3: fit using 5 models, and #
# evaluates using 10 runs of subsampling replications taking 30 percent as test:#
#
m <- sdm(sp~b15+NDVI,data=d,methods=c('glm','gam','gbm','svm','rf'),#
          replication='sub',test.percent=30,n=10)#
#
m#
# Example 3: fits using 5 models, and #
# evaluates using 10 runs of both 5-folds cross-validation and bootsrapping replication methods#
#
m <- sdm(sp~.,data=d,methods=c('gbm','tree','mars','mda','fda'),#
          replication=c('cv','boot'),cv.folds=5,n=10)#
#
m#
#
# Example 4: fit using 3 models; evaluate the models using subsampling, #
# and override the default settings for the method brt:#
#
m <- sdm(sp~b15+NDVI,data=d,methods=c('glm','gam','brt'),test.p=30,#
          modelSettings=list(brt=list(n.trees=500,train.fraction=0.8)))#
#
m
?maxent
library(dismo)
?dismo
library(ape)
trfn=""~/Downloads/Scarini_Siqueira_etal.tree"
trfn="~/Downloads/Scarini_Siqueira_etal.tree"
tr=read.tree(trfn)
tr=read.nexus(trfn)
tr
write.tree(tr,file="")
load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia_nonparallel.RData')
df
# R code to plot core usage:#
fake_y = c(df$thread_for_each_branchOp, df$thread_for_each_branchOp)#
fake_x = c(df$calc_start_time, df$calc_end_time)#
nodenum_xvals = apply(X=cbind(df$calc_start_time, df$calc_end_time), MARGIN=1, FUN=mean)#
plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 24 cores\n(numbers=node # in phylogeny)")#
colors = rainbow(n=length(unique(fake_y)))#
yvals = jitter(df$thread_for_each_branchOp)#
segments(y0=yvals, x0=df$calc_start_time, x1=df$calc_end_time, col=colors, lwd=5)#
#
# Spawn times:#
segments(y0=yvals, x0=df$calc_spawn_start, x1=df$calc_start_time, col="grey50", lwd=1, lty="dotted")#
#
# Node Indexes (Julia PhyloNetworks nodeIndex)#
text(x=nodenum_xvals, y=yvals, labels=df$nodeIndex, cex=0.5)
load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia_nonparallel.RData')
res.node_Lparent_state#
res.node_Rparent_state#
res.likes_at_each_nodeIndex_branchTop#
res.likes_at_each_nodeIndex_branchBot#
res.thread_for_each_nodeOp#
res.thread_for_each_branchOp#
res.node_state#
#
# Make a DateFrame of the node results#
df = DataFrame(nodeIndex=collect(1:res.num_nodes), thread_for_each_nodeOp=res.thread_for_each_nodeOp, thread_for_each_branchOp=res.thread_for_each_branchOp, calc_duration=res.calc_duration, calc_spawn_start=res.calc_spawn_start, calc_start_time=res.calc_start_time, calc_end_time=res.calc_end_time, node_state=res.node_state, node_Lparent_state=res.node_Lparent_state, node_Rparent_state=res.node_Rparent_state, likes_at_each_nodeIndex_branchTop=res.likes_at_each_nodeIndex_branchTop, likes_at_each_nodeIndex_branchBot=res.likes_at_each_nodeIndex_branchBot)#
#
sum(df[:,:calc_duration])#
res.calctime_iterations[1]#
sum(df[:,:calc_duration]) / res.calctime_iterations[1]#
# Save a julia DataFrame to an R data.frame#
# as an Rdata file that can be easily loaded.#
# Source: https://stackoverflow.com/questions/28084403/saving-julia-dataframe-to-read-in-r-using-hdf5/57903489#57903489#
using DataFrames#
using RCall#
include("/drives/Dropbox/_njm/__julia/julia4Rppl_v2.jl")#
pathfn = df_to_Rdata(df, fn="dfjulia_nonparallel.RData", path="/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/")#
pathfn#
#
# R code to plot core usage:#
fake_y = c(df$thread_for_each_branchOp, df$thread_for_each_branchOp)#
fake_x = c(df$calc_start_time, df$calc_end_time)#
nodenum_xvals = apply(X=cbind(df$calc_start_time, df$calc_end_time), MARGIN=1, FUN=mean)
load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia_nonparallel.RData')
fake_y = c(df$thread_for_each_branchOp, df$thread_for_each_branchOp)#
fake_x = c(df$calc_start_time, df$calc_end_time)#
nodenum_xvals = apply(X=cbind(df$calc_start_time, df$calc_end_time), MARGIN=1, FUN=mean)#
#
plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 24 cores\n(numbers=node # in phylogeny)")#
colors = rainbow(n=length(unique(fake_y)))#
yvals = jitter(df$thread_for_each_branchOp)#
segments(y0=yvals, x0=df$calc_start_time, x1=df$calc_end_time, col=colors, lwd=5)#
#
# Spawn times:#
segments(y0=yvals, x0=df$calc_spawn_start, x1=df$calc_start_time, col="grey50", lwd=1, lty="dotted")#
#
# Node Indexes (Julia PhyloNetworks nodeIndex)#
text(x=nodenum_xvals, y=yvals, labels=df$nodeIndex, cex=0.5)
colors
fake_y
# Loads to df#
load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia_nonparallel.RData')#
#
# Remove the "0" (root node threads)#
TF0 = df$thread_for_each_branchOp != 0#
df = df[TF0,]#
#
fake_y = c(df$thread_for_each_branchOp, df$thread_for_each_branchOp)#
fake_x = c(df$calc_start_time, df$calc_end_time)#
nodenum_xvals = apply(X=cbind(df$calc_start_time, df$calc_end_time), MARGIN=1, FUN=mean)#
#
plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 24 cores\n(numbers=node # in phylogeny)")#
colors = rainbow(n=length(unique(fake_y)))#
yvals = jitter(df$thread_for_each_branchOp)#
segments(y0=yvals, x0=df$calc_start_time, x1=df$calc_end_time, col=colors, lwd=5)#
#
# Spawn times:#
segments(y0=yvals, x0=df$calc_spawn_start, x1=df$calc_start_time, col="grey50", lwd=1, lty="dotted")#
#
# Node Indexes (Julia PhyloNetworks nodeIndex)#
text(x=nodenum_xvals, y=yvals, labels=df$nodeIndex, cex=0.5)
load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia.RData')#
#
# Remove the "0" (root node threads)#
TF0 = df$thread_for_each_branchOp != 0#
df = df[TF0,]#
#
fake_y = c(df$thread_for_each_branchOp, df$thread_for_each_branchOp)#
fake_x = c(df$calc_start_time, df$calc_end_time)#
nodenum_xvals = apply(X=cbind(df$calc_start_time, df$calc_end_time), MARGIN=1, FUN=mean)#
#
#plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 24 cores\n(numbers=node # in phylogeny)")#
plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 1 core\n(numbers=node # in phylogeny)", ylim=c(0.96,1.04))#
colors = rainbow(n=length(unique(fake_y)))#
yvals = jitter(df$thread_for_each_branchOp)#
segments(y0=yvals, x0=df$calc_start_time, x1=df$calc_end_time, col=colors, lwd=5)#
#
# Spawn times:#
#segments(y0=yvals, x0=df$calc_spawn_start, x1=df$calc_start_time, col="grey50", lwd=1, lty="dotted")#
#
# Node Indexes (Julia PhyloNetworks nodeIndex)#
text(x=nodenum_xvals, y=yvals, labels=df$nodeIndex, cex=0.5)
load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia.RData')#
#
# Remove the "0" (root node threads)#
TF0 = df$thread_for_each_branchOp != 0#
df = df[TF0,]#
#
fake_y = c(df$thread_for_each_branchOp, df$thread_for_each_branchOp)#
fake_x = c(df$calc_start_time, df$calc_end_time)#
nodenum_xvals = apply(X=cbind(df$calc_start_time, df$calc_end_time), MARGIN=1, FUN=mean)#
#
#plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 24 cores\n(numbers=node # in phylogeny)")#
plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 1 core\n(numbers=node # in phylogeny)")#, ylim=c(0.96,1.04))#
colors = rainbow(n=length(unique(fake_y)))#
yvals = jitter(df$thread_for_each_branchOp)#
segments(y0=yvals, x0=df$calc_start_time, x1=df$calc_end_time, col=colors, lwd=5)#
#
# Spawn times:#
#segments(y0=yvals, x0=df$calc_spawn_start, x1=df$calc_start_time, col="grey50", lwd=1, lty="dotted")#
#
# Node Indexes (Julia PhyloNetworks nodeIndex)#
text(x=nodenum_xvals, y=yvals, labels=df$nodeIndex, cex=0.5)
load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia_nonparallel.RData')#
#load('/drives/GDrive/__GDrive_projects/2018-01-22_Marsden/software/Julia_EPIRK/dfjulia.RData')#
#
# Remove the "0" (root node threads)#
TF0 = df$thread_for_each_branchOp != 0#
df = df[TF0,]#
#
fake_y = c(df$thread_for_each_branchOp, df$thread_for_each_branchOp)#
fake_x = c(df$calc_start_time, df$calc_end_time)#
nodenum_xvals = apply(X=cbind(df$calc_start_time, df$calc_end_time), MARGIN=1, FUN=mean)#
#
#plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 24 cores\n(numbers=node # in phylogeny)")#
plot(fake_x, fake_y, pch=".", col="white", xlab="time of start & end", ylab="thread ID", main="Downpass calculation spread over 1 core\n(numbers=node # in phylogeny)", ylim=c(0.96,1.04))#
colors = rainbow(n=length(unique(fake_y)))#
yvals = jitter(df$thread_for_each_branchOp)#
segments(y0=yvals, x0=df$calc_start_time, x1=df$calc_end_time, col=colors, lwd=5)#
#
# Spawn times:#
#segments(y0=yvals, x0=df$calc_spawn_start, x1=df$calc_start_time, col="grey50", lwd=1, lty="dotted")#
#
# Node Indexes (Julia PhyloNetworks nodeIndex)#
text(x=nodenum_xvals, y=yvals, labels=df$nodeIndex, cex=0.5)
install.packages("castor")
?castor
library(castor)
?castor
Nstates = 2#
Q = get_random_mk_transition_matrix(Nstates, rate_model="ARD", max_rate=0.1)#
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
fit = fit_musse(tree,#
                Nstates            = Nstates,#
                tip_pstates        = tip_states,#
                sampling_fractions = rarefaction)#
if(!fit$success){#
  cat(sprintf("ERROR: Fitting failed"))#
}else{#
  # compare fitted birth rates to true values#
  errors = (fit$parameters$birth_rates - parameters$birth_rates)#
  relative_errors = errors/parameters$birth_rates#
  cat(sprintf("BiSSE relative birth-rate errors:\n"))#
  print(relative_errors)#
}
fit
Nstates=100
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
Nstates=10
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
Nstates=50
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
Nstates=100
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
Nstates=50
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
Nstates=50
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
hist(tip_states)
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
runif(Nstates,5,10)
parameters
?fit_musse
Q = get_random_mk_transition_matrix(Nstates, rate_model="ARD", max_rate=0.1)
Q
Nstates
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
Nstates=100
Q = get_random_mk_transition_matrix(Nstates, rate_model="ARD", max_rate=0.1)#
parameters = list(birth_rates       = runif(Nstates,5,10),#
                  death_rates       = runif(Nstates,0,5),#
                  transition_matrix = Q)#
rarefaction = 0.5 # randomly omit half of the tips#
#
# Simulate a tree under the BiSSE model#
simulation = simulate_musse(Nstates, #
                            parameters         = parameters, #
                            max_tips           = 1000,#
                            sampling_fractions = rarefaction)#
tree       = simulation$tree#
tip_states = simulation$tip_states
tip_states
fit = fit_musse(tree,#
                Nstates            = Nstates,#
                tip_pstates        = tip_states,#
                sampling_fractions = rarefaction)#
if(!fit$success){#
  cat(sprintf("ERROR: Fitting failed"))#
}else{#
  # compare fitted birth rates to true values#
  errors = (fit$parameters$birth_rates - parameters$birth_rates)#
  relative_errors = errors/parameters$birth_rates#
  cat(sprintf("BiSSE relative birth-rate errors:\n"))#
  print(relative_errors)#
}
fit
?dSSE
?castor
# The following example demonstrates how to fit a MuSSE model to a large timetree using the R package castor.#
# We will use the dated angiosperm tree (31,749 tips) and woodiness trait data (woody vs. herbaceous) by Zanne et al. (2014, DOI:10.1038/nature12872)#
# The timetree and trait data are publicly available at Dryad: https://datadryad.org/resource/doi:10.5061/dryad.63q27#
# To run this script, you need to first download the timetree and trait data and place them in your current working directory, under the following names:#
#	Vascular_Plants_rooted.dated.tre#
#	GlobalWoodinessDatabase.csv#
##
# This code was tested using R v3.6.0 and castor 1.4.0, on MacOS 10.13.6.#
# On a modern Macbook Pro laptop (mid-2018) the computation should take about 1 hour.#
##
# ####################################
# DISCLAIMER#
##
# THIS SOFTWARE IS PROVIDED BY ITS CREATORS AND CONTRIBUTORS "AS IS"#
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE#
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE#
# ARE DISCLAIMED. IN NO EVENT SHALL THE CREATOR OR CONTRIBUTORS BE#
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR#
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF#
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS#
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN#
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)#
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE#
# POSSIBILITY OF SUCH DAMAGE.#
##
# ####################################
# load castor package#
require("castor")#
#
# The timetree is available at Dryad: https://datadryad.org/resource/doi:10.5061/dryad.63q27#
# The timetree ("Vascular_Plants_rooted.dated.tre") is located in the zip file "PhylogeneticResources.zip"#
# Below, we're assuming the tree has been placed into the current working directory#
tree  = castor::read_tree(file="Vascular_Plants_rooted.dated.tre", underscores_as_blanks=TRUE)#
#
# get some basic stats about the tree#
Ntips 	 = length(tree$tip.label)#
root_age = castor::get_tree_span(tree)$max_distance#
#
# To determine the sampling fraction ("rarefaction"), we need an estimate for the total number of extant angiosperm species#
# According to Joppa et al. (2011, DOI:10.1098/rspb.2010.1004) there are roughly 400,000 flowering plant species on Earth#
TOTAL_EXTANT = 400000#
rarefaction  = Ntips/TOTAL_EXTANT#
#
# The woodiness trait table ("GlobalWoodinessDatabase.csv") is available at Dryad: https://datadryad.org/resource/doi:10.5061/dryad.63q27#
# Below, we're assuming the table has been downloaded to the current working directory#
trait_table = read.table(	file = "GlobalWoodinessDatabase.csv", #
							header = TRUE, #
							sep = ",", #
							na.strings = c("unmapped","variable"), #
							stringsAsFactors = FALSE)#
# omit NA entries from trait table#
trait_table = trait_table[!is.na(trait_table[,2]),]#
# create a tip_states vector listing tip states as integers 1 & 2 (instead of the original 'W' & 'H')#
# use NA for tips with unknown woodyness#
state_map  	= castor::map_to_state_space(trait_table[,2])#
Nstates		= state_map$Nstates # number of distinct states the trait can have (will be 2 in our example)#
name2state	= setNames(state_map$mapped_states, trait_table[,1]) # prepare to map tip names to integer states#
tip_states	= unname(name2state[tree$tip.label]) # tips missing from the trait table will be assigned NA#
#
# guesstimate start lambdas & mus based on the LTT#
# lambda can be inferred from the present-day slope of the LTT, correcting for the sampling fraction#
LTT 	= castor::count_lineages_through_time(tree, Ntimes=log2(Ntips)*10, include_slopes = TRUE)#
guess 	= list()#
guess$birth_rates = tail(LTT$relative_slopes,1)/rarefaction#
guess$death_rates = guess$birth_rates # mu is typically close to lambda#
#
# specify upper bounds for the model parameters#
# this helps constrain the fitting within reasonable parameter space, preventing excessive computation time#
upper = list(transition_matrix=1e4/root_age, birth_rates=1e4/root_age, death_rates=1e4/root_age)#
#
# limit the time (seconds) spent on each likelihood evaluation#
# this further helps avoid extreme parameter regions where likelihood calculations become very slow#
max_model_runtime = max(1,Ntips/1e3)#
#
# fit MuSSE model via maximum-likelihood, without calculating confidence intervals#
# in this example, all speciation/extinction/transition rates are allowed to differ from each other#
cat(sprintf("Running %d-state MuSSE..\n",Nstates))#
fit = castor::fit_musse(tree, #
						Nstates 				= Nstates,#
						state_names				= state_map$state_names, # provide the original state descriptions (e.g., 'woody' & 'herbaceous')#
						tip_pstates				= tip_states,#
						sampling_fractions 		= rarefaction,#
						transition_rate_model	= "ARD",#
						root_prior 				= "likelihoods",#
						root_conditioning		= "madfitz",#
						Ntrials 				= 8, # repeat fitting multiple times from random start params. For greater accuracy, increase this number.#
						first_guess				= guess,#
						upper					= upper,#
						Nthreads 				= 4, # use 4 cores in parallel#
						max_model_runtime		= max_model_runtime,#
						verbose_prefix			= "  ")#
#
if(fit$success){#
	# fitting succeeded, so print results#
	cat(sprintf("MuSSE finished successfully\nLog-likelihood: %.10g\nFitted parameters:\n",fit$loglikelihood))#
	print(fit$parameters)#
}else{#
	# fitting failed, so print error message#
	cat(sprintf("ERROR: MuSSE failed, with the following error: %s\n",fit$error))#
}
remove.packages("rexpokit")#
install.packages(pkgs="/GitHub/rexpokit", repos=NULL, type="source")#
library(rexpokit)#
maxent(3.5, 1:6)
?rexpokit
Qmat = matrix(c(-1.218, 0.504, 0.336, 0.378, 0.126, -0.882, 0.252, 0.504,#
0.168, 0.504, -1.05, 0.378, 0.126, 0.672, 0.252, -1.05), nrow=4, byrow=TRUE)#
#
# Make a series of t values#
tvals = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 14)#
#
# Exponentiate each with EXPOKIT's dgpadm (good for small dense matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dgpadm_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# Exponentiate each with EXPOKIT's dmexpv (should be fast for large sparse matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dmexpv_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=2)#
#
# DGEXPV, single t-value#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=2)#
#
# These functions runs the for-loop itself (sadly, we could not get mapply() to work#
# on a function that calls dmexpv/dgexpv), returning a list of probability matrices.#
#
# DMEXPV functions#
list_of_P_matrices_dmexpv = expokit_wrapalldmexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dmexpv#
#
# DGEXPV functions#
list_of_P_matrices_dgexpv = expokit_wrapalldgexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dgexpv#
#
# Check if there are differences in the results (might only happen for large problems)#
cat("\n")#
cat("Differences between dmexpv and dgexpv\n")#
#
for (i in 1:length(list_of_P_matrices_dmexpv))#
	{#
	diffs = list_of_P_matrices_dmexpv[[i]] - list_of_P_matrices_dgexpv[[i]]#
	print(diffs)#
	cat("\n")#
	}
########################################################
# Compare ClaSSE and BiSSE calculations#
##
# E.g.:#
# diversitree versus plain-R#
# diversitree versus BioGeoBEARS+Yule+BFs#
# #
########################################################
#
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_4states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_4states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q21"] = e_val#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q24"] = d_val#
classe_params[param_names == "q34"] = d_val#
classe_params[param_names == "q42"] = e_val#
classe_params[param_names == "q43"] = e_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Null range cannot speciate (doesn't seem to matter anyway,#
# as "null" cannot be an ancestor anyway)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = birthRate#
classe_params[param_names=="lambda333"] = birthRate#
classe_params[param_names=="lambda444"] = birthRate#
not='#
classe_params[param_names=="lambda111"] = birthRate#
#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = yprob * birthRate#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda223"] = jprob * birthRate#
classe_params[param_names=="lambda323"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda424"] = 1/6 * birthRate#
classe_params[param_names=="lambda434"] = 1/6 * birthRate#
#
# Vicariance for state AB#
classe_params[param_names=="lambda423"] = 1/6 * birthRate#
'#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_4states)#
#
classe_4states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 0, 1)#
res5 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 0, 1)#
res5t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25,0.25,0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.EQUI, condition.surv=FALSE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
loglik = log(sum(equilibrium_root_freqs * d_root_orig)) + sum(lq)#
loglik#
# -12.269765 matches!#
# If root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
root.p = d_root_orig/sum(d_root_orig)#
lambda <- classe_params[E_indices]#
e.root <- vals[E_indices]#
#
# BiSSE#
#d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
# MuSSE/ClaSSE#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=TRUE#
root.p = rep(1/nstates, times=nstates)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0.25,0.25,0.25,0.25)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=TRUE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0, 0, 0, 1)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
# If root=ROOT.EQUI, condition.surv=TRUE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(equilibrium_root_freqs * lambda * (1 - e.root)^2)#
loglik = log(sum(equilibrium_root_freqs * d.root)) + sum(lq)#
loglik#
# -12.94599 matches!#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Get Es,Ds matrix#
probs_branch_bottoms = base * exp(attr(res2, "intermediates")$lq)#
probs_branch_bottoms[1,]
attr(res2, "intermediates")$lq
nstates
base
Dindexes = (nstates+1):(nstates*2)#
probs_branch_bottoms = base#
probs_branch_bottoms[,Dindexes]
exp(attr(res2, "intermediates")$lq)
probs_branch_bottoms[,Dindexes] * t(exp(attr(res2, "intermediates")$lq))
probs_branch_bottoms[,Dindexes]
t(exp(attr(res2, "intermediates")$lq))
probs_branch_bottoms[,Dindexes] * exp(attr(res2, "intermediates")$lq)
Dindexes = (nstates+1):(nstates*2)#
EsDs_branch_bottoms = base#
EsDs_branch_bottoms[,Dindexes] = EsDs_branch_bottoms[,Dindexes] * exp(attr(res2, "intermediates")$lq)#
EsDs_branch_bottoms[1,]
/drives/GDrive/__GDrive_projects/2019-02-19_Juan_rails_traits/z_blank_traits_analyses/make_plot_best_model
