install.packages("LaplacesDemon")
library(LaplacesDemon)
pwd
?LaplacesDemon
data(demonsnacks)#
y <- log(demonsnacks$Calories)#
X <- cbind(1, as.matrix(log(demonsnacks[,c(1,4,10)]+1)))#
J <- ncol(X)#
for (j in 2:J) X[,j] <- CenterScale(X[,j])
demonsnacks
corplot(demonsnakcs)
corplot(demonsnacks)
pairs(demonsnacks)
pairs(log(demonsnacks))
?demonsnacks
snacks[,c(1,4,10)]+1
data(demonsnacks)#
snacks = demonsnacks
snacks[,c(1,4,10)]+1
# The predictors (serving size, saturated fat, and protein) will be stored in X#
# Also, we are taking the log (natural log)#
X <- cbind(1, as.matrix(log(snacks[,c(1,4,10)]+1)))#
J <- ncol(X)
library(LaplacesDemon)#
#
# Load some example data (nutritional info on snack packages, see ?demonsnacks)#
data(demonsnacks)#
snacks = demonsnacks#
#
# The thing you are trying to predict (amount of Calories) will be stored in "y"#
y <- log(snacks$Calories)#
#
# The predictors (serving size, saturated fat, and protein) will be stored in X#
# Also, we are taking the log (natural log)#
X <- cbind(1, as.matrix(log(snacks[,c(1,4,10)]+1)))#
#
# Center-Scale the variables#
for (j in 2:ncol(X))#
	{#
	X[,j] <- CenterScale(X[,j])#
	}
X
?CenterScale
library(LaplacesDemon)#
#
# Load some example data (nutritional info on snack packages, see ?demonsnacks)#
data(demonsnacks)#
snacks = demonsnacks#
#
# The thing you are trying to predict (amount of Calories) will be stored in "y"#
y <- log(snacks$Calories)#
#
# The predictors (serving size, saturated fat, and protein) will be stored in X#
# Also, we are taking the log (natural log)#
X <- cbind(1, as.matrix(log(snacks[,c(1,4,10)]+1)))#
#
# J is number of columns in X#
J = ncol(X)#
#
# Center-Scale the variables#
for (j in 2:J)#
	{#
	X[,j] <- CenterScale(X[,j])#
	}#
#########################  Data List Preparation  ##########################
mon.names <- "LP"#
parm.names <- as.parm.names(list(beta=rep(0,J), sigma=0))#
pos.beta <- grep("beta", parm.names)#
pos.sigma <- grep("sigma", parm.names)#
PGF <- function(Data) {#
     beta <- rnorm(Data$J)#
     sigma <- runif(1)#
     return(c(beta, sigma))#
     }#
MyData <- list(J=J, PGF=PGF, X=X, mon.names=mon.names,#
     parm.names=parm.names, pos.beta=pos.beta, pos.sigma=pos.sigma, y=y)
?PGF
mon.names <- "LP"#
parm.names <- as.parm.names(list(beta=rep(0,J), sigma=0))#
pos.beta <- grep("beta", parm.names)#
pos.sigma <- grep("sigma", parm.names)
parm.names
list(beta=rep(0,J), sigma=0)
?as.parm.names
PGF <- function(Data)#
	{#
	beta <- rnorm(Data$J)#
	sigma <- runif(1)#
	return(c(beta, sigma))#
	}#
MyData <- list(J=J, PGF=PGF, X=X, mon.names=mon.names,#
     parm.names=parm.names, pos.beta=pos.beta, pos.sigma=pos.sigma, y=y)
MyData
Model <- function(parm, Data)#
     {#
     ### Parameters#
     beta <- parm[Data$pos.beta]#
     sigma <- interval(parm[Data$pos.sigma], 1e-100, Inf)#
     parm[Data$pos.sigma] <- sigma#
     ### Log-Prior#
     beta.prior <- sum(dnormv(beta, 0, 1000, log=TRUE))#
     sigma.prior <- dhalfcauchy(sigma, 25, log=TRUE)#
     ### Log-Likelihood#
     mu <- tcrossprod(Data$X, t(beta))#
     LL <- sum(dnorm(Data$y, mu, sigma, log=TRUE))#
     ### Log-Posterior#
     LP <- LL + beta.prior + sigma.prior#
     Modelout <- list(LP=LP, Dev=-2*LL, Monitor=LP,#
          yhat=rnorm(length(mu), mu, sigma), parm=parm)#
     return(Modelout)#
     }
Initial.Values <- GIV(Model, MyData, PGF=TRUE)
Initial.Values
Fit <- LaplacesDemon(Model, Data=MyData, Initial.Values,#
    Covar=NULL, Iterations=1000, Status=100, Thinning=1,#
    Algorithm="MCMCMC", Specs=list(lambda=1, CPUs=2, Packages=NULL,#
    Dyn.libs=NULL))
Fi
Fit
Fit <- LaplacesDemon(Model, Data=MyData, Initial.Values,#
    Covar=NULL, Iterations=1000000, Status=100, Thinning=100,#
    Algorithm="MCMCMC", Specs=list(lambda=1, CPUs=2, Packages=NULL,#
    Dyn.libs=NULL))
library(GenSA)    # GenSA is better than optimx (although somewhat slower)#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
#
########################################################
# 2018-10-10 update: I have been putting the #
# updates on CRAN/GitHub#
# You should use:#
# rexpokit version 0.26.6 from CRAN#
# cladoRcpp version 0.15 from CRAN#
# BioGeoBEARS version 1.1 from GitHub, install with:#
# library(devtools)#
# devtools::install_github(repo="nmatzke/BioGeoBEARS")#
########################################################
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
########################################################
# CUT: The old instructions to source() online upgrade .R files have been deleted,#
#         all updates are now on the GitHub version of the package, version 1.1+#
########################################################
#
########################################################
# (This local-sourcing is mostly useful for Nick, while actively developing)#
# Local source()-ing method -- uses BioGeoBEARS sourceall() function #
# on a directory of .R files, so you don't have to type them out.#
# The directories here are on my machine, you would have to make a #
# directory, save the .R files there, and refer to them.#
##
# NOTE: it's best to source the "cladoRcpp.R" update first, to avoid warnings like this:#
###
## Note: possible error in 'rcpp_calc_anclikes_sp_COOweights_faster(Rcpp_leftprobs = tmpca_1, ': #
##         unused arguments (m = m, m_null_range = include_null_range, jts_matrix = jts_matrix) #
###
##
# TO USE: Delete or comment out the 'source("http://...")' commands above, and un-comment#
#              the below...#
#########################################################################
# Un-comment (and fix directory paths) to use:#
#library(BioGeoBEARS)#
#source("/drives/Dropbox/_njm/__packages/cladoRcpp_setup/cladoRcpp.R")#
#sourceall("/drives/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#calc_loglike_sp = compiler::cmpfun(calc_loglike_sp_prebyte)    # crucial to fix bug in uppass calculations#
#calc_independent_likelihoods_on_each_branch = compiler::cmpfun(calc_independent_likelihoods_on_each_branch_prebyte)#
#########################################################################
#
########################################################
# SETUP: YOUR WORKING DIRECTORY#
########################################################
# You will need to set your working directory to match your local system#
#
# Note these very handy functions!#
# Command "setwd(x)" sets your working directory#
# Command "getwd()" gets your working directory and tells you what it is.#
# Command "list.files()" lists the files in your working directory#
# To get help on any command, use "?".  E.g., "?list.files"#
#
# Set your working directory for output files#
# default here is your home directory ("~")#
# Change this as you like#
wd = np("~")#
setwd(wd)#
#
# Double-check your working directory with getwd()#
getwd()#
#
########################################################
# SETUP: Extension data directory#
########################################################
# When R packages contain extra files, they are stored in the "extdata" directory #
# inside the installed package.#
##
# BioGeoBEARS contains various example files and scripts in its extdata directory.#
# #
# Each computer operating system might install BioGeoBEARS in a different place, #
# depending on your OS and settings. #
# #
# However, you can find the extdata directory like this:#
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny (plots to a PDF, which avoids issues with multiple graphics in same window):#
pdffn = "tree.pdf"#
pdf(file=pdffn, width=9, height=12)#
#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)#
#
########################################################
# Geography file#
# Notes:#
# 1. This is a PHYLIP-formatted file. This means that in the #
#    first line, #
#    - the 1st number equals the number of rows (species)#
#    - the 2nd number equals the number of columns (number of areas)#
#    - after a tab, put the areas in parentheses, with spaces: (A B C D)#
##
# 1.5. Example first line:#
#    10    4    (A B C D)#
# #
# 2. The second line, and subsequent lines:#
#    speciesA    0110#
#    speciesB    0111#
#    speciesC    0001#
#         ...#
# #
# 2.5a. This means a TAB between the species name and the area 0/1s#
# 2.5b. This also means NO SPACE AND NO TAB between the area 0/1s.#
# #
# 3. See example files at:#
#    http://phylo.wikidot.com/biogeobears#files#
# #
# 4. Make you understand what a PLAIN-TEXT EDITOR is:#
#    http://phylo.wikidot.com/biogeobears#texteditors#
##
# 3. The PHYLIP format is the same format used for C++ LAGRANGE geography files.#
##
# 4. All names in the geography file must match names in the phylogeny file.#
##
# 5. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
##
# 6. Operational taxonomic units (OTUs) should ideally be phylogenetic lineages, #
#    i.e. genetically isolated populations.  These may or may not be identical #
#    with species.  You would NOT want to just use specimens, as each specimen #
#    automatically can only live in 1 area, which will typically favor DEC+J #
#    models.  This is fine if the species/lineages really do live in single areas,#
#    but you wouldn't want to assume this without thinking about it at least. #
#    In summary, you should collapse multiple specimens into species/lineages if #
#    data indicates they are the same genetic population.#
#######################################################
#
# This is the example geography file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))#
#
# Look at the raw geography text file:#
moref(geogfn)#
#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Set the maximum number of areas any species may occupy; this cannot be larger #
# than the number of areas you set up, but it can be smaller.#
max_range_size = 4#
#
#####################################################
#####################################################
# KEY HINT: The number of states (= number of different possible geographic ranges)#
# depends on (a) the number of areas and (b) max_range_size.#
# If you have more than about 500-600 states, the calculations will get REALLY slow,#
# since the program has to exponentiate a matrix of e.g. 600x600.  Often the computer#
# will just sit there and crunch, and never get through the calculation of the first#
# likelihood.#
# #
# (this is also what is usually happening when LAGRANGE hangs: you have too many states!)#
##
# To check the number of states for a given number of ranges, try:#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=FALSE)#
numstates_from_numareas(numareas=4, maxareas=3, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=2, include_null_range=TRUE)#
#
# Large numbers of areas have problems:#
numstates_from_numareas(numareas=10, maxareas=10, include_null_range=TRUE)#
#
# ...unless you limit the max_range_size:#
numstates_from_numareas(numareas=10, maxareas=2, include_null_range=TRUE)#
#####################################################
#####################################################
#
########################################################
########################################################
# DEC AND DEC+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DEC" model is identical with #
# the Lagrange DEC model, and should return identical#
# ML estimates of parameters, and the same #
# log-likelihoods, for the same datasets.#
##
# Ancestral state probabilities at nodes will be slightly #
# different, since BioGeoBEARS is reporting the #
# ancestral state probabilities under the global ML#
# model, and Lagrange is reporting ancestral state#
# probabilities after re-optimizing the likelihood#
# after fixing the state at each node. These will #
# be similar, but not identical. See Matzke (2014),#
# Systematic Biology, for discussion.#
##
# Also see Matzke (2014) for presentation of the #
# DEC+J model.#
########################################################
########################################################
#
########################################################
########################################################
#
########################################################
# Run DEC#
########################################################
#
# Intitialize a default model (DEC model)#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
# Give BioGeoBEARS the location of the phylogeny Newick file#
BioGeoBEARS_run_object$trfn = trfn#
#
# Give BioGeoBEARS the location of the geography text file#
BioGeoBEARS_run_object$geogfn = geogfn#
#
# Input the maximum range size#
BioGeoBEARS_run_object$max_range_size = max_range_size#
#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
# 1. Here, un-comment ONLY the files you want to use.#
# 2. Also un-comment "BioGeoBEARS_run_object = section_the_tree(...", below.#
# 3. For example files see (a) extdata_dir, #
#  or (b) http://phylo.wikidot.com/biogeobears#files#
#  and BioGeoBEARS Google Group posts for further hints)#
##
# Uncomment files you wish to use in time-stratified analyses:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
# (use more cores to speed it up; this requires#
# library(parallel) and/or library(snow). The package "parallel" #
# is now default on Macs in R 3.0+, but apparently still #
# has to be typed on some Windows machines. Note: apparently #
# parallel works on Mac command-line R, but not R.app.#
# BioGeoBEARS checks for this and resets to 1#
# core with R.app)#
#
# Sparse matrix exponentiation is an option for huge numbers of ranges/states (600+)#
# I have experimented with sparse matrix exponentiation in EXPOKIT/rexpokit,#
# but the results are imprecise and so I haven't explored it further.#
# In a Bayesian analysis, it might work OK, but the ML point estimates are#
# not identical.#
# Also, I have not implemented all functions to work with force_sparse=TRUE.#
# Volunteers are welcome to work on it!!#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC model#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
# Run this to check inputs. Read the error messages if you get them!#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = TRUE#
resfn = "Psychotria_DEC_M0_unconstrained_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDEC = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDEC = res#
    }
get_Qmat_COOmat_from_BioGeoBEARS_run_object(BioGeoBEARS_run_object)
########################################################
# Run DEC+J#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC+J model#
# Get the ML parameter values from the 2-parameter nested model#
# (this will ensure that the 3-parameter model always does at least as good)#
dstart = resDEC$outputs@params_table["d","est"]#
estart = resDEC$outputs@params_table["e","est"]#
jstart = 0.0001#
#
# Input starting values for d, e#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = estart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = estart#
#
# Add j as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
resfn = "Psychotria_DEC+J_M0_unconstrained_v1.Rdata"#
runslow = TRUE#
if (runslow)#
    {#
    #sourceall("/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
#
    resDECj = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDECj = res#
    }
get_Qmat_COOmat_from_BioGeoBEARS_run_object(BioGeoBEARS_run_object)
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table
168*26.73
library(BioGeoBEARS)
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny (plots to a PDF, which avoids issues with multiple graphics in same window):#
pdffn = "tree.pdf"#
pdf(file=pdffn, width=9, height=12)#
#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)#
#
########################################################
# Geography file#
# Notes:#
# 1. This is a PHYLIP-formatted file. This means that in the #
#    first line, #
#    - the 1st number equals the number of rows (species)#
#    - the 2nd number equals the number of columns (number of areas)#
#    - after a tab, put the areas in parentheses, with spaces: (A B C D)#
##
# 1.5. Example first line:#
#    10    4    (A B C D)#
# #
# 2. The second line, and subsequent lines:#
#    speciesA    0110#
#    speciesB    0111#
#    speciesC    0001#
#         ...#
# #
# 2.5a. This means a TAB between the species name and the area 0/1s#
# 2.5b. This also means NO SPACE AND NO TAB between the area 0/1s.#
# #
# 3. See example files at:#
#    http://phylo.wikidot.com/biogeobears#files#
# #
# 4. Make you understand what a PLAIN-TEXT EDITOR is:#
#    http://phylo.wikidot.com/biogeobears#texteditors#
##
# 3. The PHYLIP format is the same format used for C++ LAGRANGE geography files.#
##
# 4. All names in the geography file must match names in the phylogeny file.#
##
# 5. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
##
# 6. Operational taxonomic units (OTUs) should ideally be phylogenetic lineages, #
#    i.e. genetically isolated populations.  These may or may not be identical #
#    with species.  You would NOT want to just use specimens, as each specimen #
#    automatically can only live in 1 area, which will typically favor DEC+J #
#    models.  This is fine if the species/lineages really do live in single areas,#
#    but you wouldn't want to assume this without thinking about it at least. #
#    In summary, you should collapse multiple specimens into species/lineages if #
#    data indicates they are the same genetic population.#
#######################################################
#
# This is the example geography file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))#
#
# Look at the raw geography text file:#
moref(geogfn)#
#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Set the maximum number of areas any species may occupy; this cannot be larger #
# than the number of areas you set up, but it can be smaller.#
max_range_size = 4#
#
#####################################################
#####################################################
# KEY HINT: The number of states (= number of different possible geographic ranges)#
# depends on (a) the number of areas and (b) max_range_size.#
# If you have more than about 500-600 states, the calculations will get REALLY slow,#
# since the program has to exponentiate a matrix of e.g. 600x600.  Often the computer#
# will just sit there and crunch, and never get through the calculation of the first#
# likelihood.#
# #
# (this is also what is usually happening when LAGRANGE hangs: you have too many states!)#
##
# To check the number of states for a given number of ranges, try:#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=FALSE)#
numstates_from_numareas(numareas=4, maxareas=3, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=2, include_null_range=TRUE)#
#
# Large numbers of areas have problems:#
numstates_from_numareas(numareas=10, maxareas=10, include_null_range=TRUE)#
#
# ...unless you limit the max_range_size:#
numstates_from_numareas(numareas=10, maxareas=2, include_null_range=TRUE)#
#####################################################
#####################################################
#
########################################################
########################################################
# DEC AND DEC+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DEC" model is identical with #
# the Lagrange DEC model, and should return identical#
# ML estimates of parameters, and the same #
# log-likelihoods, for the same datasets.#
##
# Ancestral state probabilities at nodes will be slightly #
# different, since BioGeoBEARS is reporting the #
# ancestral state probabilities under the global ML#
# model, and Lagrange is reporting ancestral state#
# probabilities after re-optimizing the likelihood#
# after fixing the state at each node. These will #
# be similar, but not identical. See Matzke (2014),#
# Systematic Biology, for discussion.#
##
# Also see Matzke (2014) for presentation of the #
# DEC+J model.#
########################################################
########################################################
#
########################################################
########################################################
#
########################################################
# Run DEC#
########################################################
#
# Intitialize a default model (DEC model)#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
# Give BioGeoBEARS the location of the phylogeny Newick file#
BioGeoBEARS_run_object$trfn = trfn#
#
# Give BioGeoBEARS the location of the geography text file#
BioGeoBEARS_run_object$geogfn = geogfn#
#
# Input the maximum range size#
BioGeoBEARS_run_object$max_range_size = max_range_size#
#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
# 1. Here, un-comment ONLY the files you want to use.#
# 2. Also un-comment "BioGeoBEARS_run_object = section_the_tree(...", below.#
# 3. For example files see (a) extdata_dir, #
#  or (b) http://phylo.wikidot.com/biogeobears#files#
#  and BioGeoBEARS Google Group posts for further hints)#
##
# Uncomment files you wish to use in time-stratified analyses:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
# (use more cores to speed it up; this requires#
# library(parallel) and/or library(snow). The package "parallel" #
# is now default on Macs in R 3.0+, but apparently still #
# has to be typed on some Windows machines. Note: apparently #
# parallel works on Mac command-line R, but not R.app.#
# BioGeoBEARS checks for this and resets to 1#
# core with R.app)#
#
# Sparse matrix exponentiation is an option for huge numbers of ranges/states (600+)#
# I have experimented with sparse matrix exponentiation in EXPOKIT/rexpokit,#
# but the results are imprecise and so I haven't explored it further.#
# In a Bayesian analysis, it might work OK, but the ML point estimates are#
# not identical.#
# Also, I have not implemented all functions to work with force_sparse=TRUE.#
# Volunteers are welcome to work on it!!#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC model#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
# Run this to check inputs. Read the error messages if you get them!#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = TRUE#
resfn = "Psychotria_DEC_M0_unconstrained_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDEC = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDEC = res#
    }
names(res)
29,747  /
29,747  / 25,867
29747  / 25867
28402 /  24698
123489 * 0.2
123489+107+1746
125342*0.2
86572 -  92303
26763 - 21226
8149.01	+ 8347.91+ 8552.94
25049.86-21226
26763-21226
5537+2138
5537+2191
7671 + 8348 + 8553 + 2191
120000 * 0.2 * 1.15
126000 * 0.2 * 1.15
7827.28-5537
28980-27600
7827.28-5537
2,138 ''
$86,572
$92,303
92303 / 86014
86572 / 75280
92303 / 82992
92303 / 80263
92303-86572
5731+2191
5731+2138
library(Rcpp)
library(RcppArmadillo)
.libPaths()
R.home('include')
library(rexpokit)
sessionInfo()
library(rexpokit)
sessionInfo()
?rexpokit
library(rexpokit)#
#
# Make a square instantaneous rate matrix (Q matrix)#
# This matrix is taken from Peter Foster's (2001) "The Idiot's Guide#
# to the Zen of Likelihood in a Nutshell in Seven Days for Dummies,#
# Unleashed" at:#
# \url{http://www.bioinf.org/molsys/data/idiots.pdf}#
##
# The Q matrix includes the stationary base freqencies, which Pmat#
# converges to as t becomes large.#
Qmat = matrix(c(-1.218, 0.504, 0.336, 0.378, 0.126, -0.882, 0.252, 0.504,#
0.168, 0.504, -1.05, 0.378, 0.126, 0.672, 0.252, -1.05), nrow=4, byrow=TRUE)#
#
# Make a series of t values#
tvals = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 14)#
#
# Exponentiate each with EXPOKIT's dgpadm (good for small dense matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dgpadm_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# Exponentiate each with EXPOKIT's dmexpv (should be fast for large sparse matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dmexpv_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# DMEXPV and DGEXPV are designed for large, sparse Q matrices (sparse = lots of zeros).#
# DMEXPV is specifically designed for Markov chains and so may be slower, but more accurate.#
#
# DMEXPV, single t-value#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=2)#
#
# DGEXPV, single t-value#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=2)#
#
# These functions runs the for-loop itself (sadly, we could not get mapply() to work#
# on a function that calls dmexpv/dgexpv), returning a list of probability matrices.#
#
# DMEXPV functions#
list_of_P_matrices_dmexpv = expokit_wrapalldmexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dmexpv#
#
# DGEXPV functions#
list_of_P_matrices_dgexpv = expokit_wrapalldgexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dgexpv#
#
# Check if there are differences in the results (might only happen for large problems)#
cat("\n")#
cat("Differences between dmexpv and dgexpv\n")#
#
for (i in 1:length(list_of_P_matrices_dmexpv))#
	{#
	diffs = list_of_P_matrices_dmexpv[[i]] - list_of_P_matrices_dgexpv[[i]]#
	print(diffs)#
	cat("\n")#
	}
?rexpokit
x <- matrix(1:25, nrow=5)/100#
#
expm(x)
library(rexpokit)
x <- matrix(1:25, nrow=5)/100#
#
expm(x)
?rexpokit
library(rexpokit)#
#
# Make a square instantaneous rate matrix (Q matrix)#
# This matrix is taken from Peter Foster's (2001) "The Idiot's Guide#
# to the Zen of Likelihood in a Nutshell in Seven Days for Dummies,#
# Unleashed" at:#
# \url{http://www.bioinf.org/molsys/data/idiots.pdf}#
##
# The Q matrix includes the stationary base freqencies, which Pmat#
# converges to as t becomes large.#
Qmat = matrix(c(-1.218, 0.504, 0.336, 0.378, 0.126, -0.882, 0.252, 0.504,#
0.168, 0.504, -1.05, 0.378, 0.126, 0.672, 0.252, -1.05), nrow=4, byrow=TRUE)#
#
# Make a series of t values#
tvals = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 14)#
#
# Exponentiate each with EXPOKIT's dgpadm (good for small dense matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dgpadm_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}
# Exponentiate each with EXPOKIT's dmexpv (should be fast for large sparse matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dmexpv_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# DMEXPV and DGEXPV are designed for large, sparse Q matrices (sparse = lots of zeros).#
# DMEXPV is specifically designed for Markov chains and so may be slower, but more accurate.#
#
# DMEXPV, single t-value#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=2)#
#
# DGEXPV, single t-value#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=2)#
#
# These functions runs the for-loop itself (sadly, we could not get mapply() to work#
# on a function that calls dmexpv/dgexpv), returning a list of probability matrices.#
#
# DMEXPV functions#
list_of_P_matrices_dmexpv = expokit_wrapalldmexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dmexpv#
#
# DGEXPV functions#
list_of_P_matrices_dgexpv = expokit_wrapalldgexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dgexpv#
#
# Check if there are differences in the results (might only happen for large problems)#
cat("\n")#
cat("Differences between dmexpv and dgexpv\n")#
#
for (i in 1:length(list_of_P_matrices_dmexpv))#
	{#
	diffs = list_of_P_matrices_dmexpv[[i]] - list_of_P_matrices_dgexpv[[i]]#
	print(diffs)#
	cat("\n")#
	}
sessionInfo()
remove.packages("rexpokit")
library(rexpokit)
?rexpokit
library(rexpokit)#
#
# Make a square instantaneous rate matrix (Q matrix)#
# This matrix is taken from Peter Foster's (2001) "The Idiot's Guide#
# to the Zen of Likelihood in a Nutshell in Seven Days for Dummies,#
# Unleashed" at:#
# \url{http://www.bioinf.org/molsys/data/idiots.pdf}#
##
# The Q matrix includes the stationary base freqencies, which Pmat#
# converges to as t becomes large.#
Qmat = matrix(c(-1.218, 0.504, 0.336, 0.378, 0.126, -0.882, 0.252, 0.504,#
0.168, 0.504, -1.05, 0.378, 0.126, 0.672, 0.252, -1.05), nrow=4, byrow=TRUE)#
#
# Make a series of t values#
tvals = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 14)#
#
# Exponentiate each with EXPOKIT's dgpadm (good for small dense matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dgpadm_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# Exponentiate each with EXPOKIT's dmexpv (should be fast for large sparse matrices)#
for (t in tvals)#
	{#
	Pmat = expokit_dmexpv_Qmat(Qmat=Qmat, t=t, transpose_needed=TRUE)#
	cat("\n\nTime=", t, "\n", sep="")#
	print(Pmat)#
	}#
#
# DMEXPV and DGEXPV are designed for large, sparse Q matrices (sparse = lots of zeros).#
# DMEXPV is specifically designed for Markov chains and so may be slower, but more accurate.#
#
# DMEXPV, single t-value#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldmexpv_tvals(Qmat=Qmat, tvals=2)#
#
# DGEXPV, single t-value#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=tvals[1], transpose_needed=TRUE)#
expokit_wrapalldgexpv_tvals(Qmat=Qmat, tvals=2)#
#
# These functions runs the for-loop itself (sadly, we could not get mapply() to work#
# on a function that calls dmexpv/dgexpv), returning a list of probability matrices.#
#
# DMEXPV functions#
list_of_P_matrices_dmexpv = expokit_wrapalldmexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dmexpv#
#
# DGEXPV functions#
list_of_P_matrices_dgexpv = expokit_wrapalldgexpv_tvals(Qmat=Qmat,#
tvals=tvals, transpose_needed=TRUE)#
list_of_P_matrices_dgexpv#
#
# Check if there are differences in the results (might only happen for large problems)#
cat("\n")#
cat("Differences between dmexpv and dgexpv\n")#
#
for (i in 1:length(list_of_P_matrices_dmexpv))#
	{#
	diffs = list_of_P_matrices_dmexpv[[i]] - list_of_P_matrices_dgexpv[[i]]#
	print(diffs)#
	cat("\n")#
	}
65/80
75/80
library(BioGeoBEARS)
bears_optim_run
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_4states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_4states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q21"] = e_val#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q24"] = d_val#
classe_params[param_names == "q34"] = d_val#
classe_params[param_names == "q42"] = e_val#
classe_params[param_names == "q43"] = e_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Null range cannot speciate (doesn't seem to matter anyway,#
# as "null" cannot be an ancestor anyway)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = birthRate#
classe_params[param_names=="lambda333"] = birthRate#
classe_params[param_names=="lambda444"] = birthRate#
not='#
classe_params[param_names=="lambda111"] = birthRate#
#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = yprob * birthRate#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda223"] = jprob * birthRate#
classe_params[param_names=="lambda323"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda424"] = 1/6 * birthRate#
classe_params[param_names=="lambda434"] = 1/6 * birthRate#
#
# Vicariance for state AB#
classe_params[param_names=="lambda423"] = 1/6 * birthRate#
'#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_4states)#
#
classe_4states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 0, 1)#
res5 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 0, 1)#
res5t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25,0.25,0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:10,human:10):10,gorilla:20);"#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_4states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_4states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q21"] = e_val#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q24"] = d_val#
classe_params[param_names == "q34"] = d_val#
classe_params[param_names == "q42"] = e_val#
classe_params[param_names == "q43"] = e_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Null range cannot speciate (doesn't seem to matter anyway,#
# as "null" cannot be an ancestor anyway)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = birthRate#
classe_params[param_names=="lambda333"] = birthRate#
classe_params[param_names=="lambda444"] = birthRate#
not='#
classe_params[param_names=="lambda111"] = birthRate#
#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = yprob * birthRate#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda223"] = jprob * birthRate#
classe_params[param_names=="lambda323"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda424"] = 1/6 * birthRate#
classe_params[param_names=="lambda434"] = 1/6 * birthRate#
#
# Vicariance for state AB#
classe_params[param_names=="lambda423"] = 1/6 * birthRate#
'#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_4states)#
#
classe_4states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 0, 1)#
res5 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 0, 1)#
res5t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25,0.25,0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:10,human:10):10,gorilla:20);"#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_4states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_4states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q21"] = e_val#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q24"] = d_val#
classe_params[param_names == "q34"] = d_val#
classe_params[param_names == "q42"] = e_val#
classe_params[param_names == "q43"] = e_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Null range cannot speciate (doesn't seem to matter anyway,#
# as "null" cannot be an ancestor anyway)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = birthRate#
classe_params[param_names=="lambda333"] = birthRate#
classe_params[param_names=="lambda444"] = birthRate#
not='#
classe_params[param_names=="lambda111"] = birthRate#
#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = yprob * birthRate#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda223"] = jprob * birthRate#
classe_params[param_names=="lambda323"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda424"] = 1/6 * birthRate#
classe_params[param_names=="lambda434"] = 1/6 * birthRate#
#
# Vicariance for state AB#
classe_params[param_names=="lambda423"] = 1/6 * birthRate#
'#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_4states)#
#
classe_4states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 0, 1)#
res5 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 0, 1)#
res5t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25,0.25,0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
trstr = "((chimp:10,human:10):10,gorilla:20);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_4states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_4states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q21"] = e_val#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q24"] = d_val#
classe_params[param_names == "q34"] = d_val#
classe_params[param_names == "q42"] = e_val#
classe_params[param_names == "q43"] = e_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Null range cannot speciate (doesn't seem to matter anyway,#
# as "null" cannot be an ancestor anyway)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = birthRate#
classe_params[param_names=="lambda333"] = birthRate#
classe_params[param_names=="lambda444"] = birthRate#
not='#
classe_params[param_names=="lambda111"] = birthRate#
#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = yprob * birthRate#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda223"] = jprob * birthRate#
classe_params[param_names=="lambda323"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda424"] = 1/6 * birthRate#
classe_params[param_names=="lambda434"] = 1/6 * birthRate#
#
# Vicariance for state AB#
classe_params[param_names=="lambda423"] = 1/6 * birthRate#
'#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_4states)#
#
classe_4states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 0, 1)#
res5 = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_4states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_4states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25,0.25)#
res3t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.1, 0.7)#
res4t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 0, 1)#
res5t = classe_4states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_4states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25,0.25,0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:10,human:10):10,gorilla:20);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_4states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_4states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0
classe_params
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Null range cannot speciate (doesn't seem to matter anyway,#
# as "null" cannot be an ancestor anyway)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = birthRate#
classe_params[param_names=="lambda333"] = birthRate#
classe_params[param_names=="lambda444"] = birthRate
classe_params
classe_params[param_names=="lambda444"]
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = yprob * birthRate#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params
classe_params_DEC
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:10,human:10):10,gorilla:20);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params
classe_params_DEC
dput(classe_3states)
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25,0.25,0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:10,human:10):10,gorilla:20);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.1#
e_val = 0.01#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:10,human:10):10,gorilla:20);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
states
classe_params
argnames(classe_3states)
cd("/GitHub/BioGeoJulia.jl/notes/")#
#include("tst_Flow.jl")#
#
include("ModelLikes.jl")#
import .ModelLikes#
#using .Tmp#
#
include("Flow.jl")#
import .Flow#
#
using LinearAlgebra  # for "I" in: Matrix{Float64}(I, 2, 2)#
										 # https://www.reddit.com/r/Julia/comments/9cfosj/identity_matrix_in_julia_v10/#
using Profile     # for @profile#
using DataFrames  # for DataFrame#
using PhyloNetworks#
using BioGeoJulia.TrUtils # for flat2() (similar to unlist)#
using BioGeoJulia.StateSpace#
using BioGeoJulia.TreePass#
using BioGeoJulia.SSEs#
#
using DifferentialEquations#
using OrdinaryDiffEq, Sundials, DiffEqDevTools, Plots, ODEInterfaceDiffEq, ODE, LSODA#
#Pkg.add(PackageSpec(url="https://github.com/JuliaDiffEq/deSolveDiffEq.jl"))#
#using deSolveDiffEq #
# https://docs.juliadiffeq.org/stable/solvers/ode_solve/index.html#
#
using Profile     # for @profile#
using DataFrames  # for DataFrame#
using PhyloNetworks#
#
inputs = ModelLikes.setup_DEC_SSE(2, readTopology("((chimp:1,human:1):1,gorilla:2);"))#
#inputs = ModelLikes.setup_MuSSE(2, readTopology("((chimp:10,human:10):10,gorilla:20);"))#
res = inputs.res#
trdf = inputs.trdf#
n = inputs.p_Ds_v5.n#
solver_options = inputs.solver_options#
solver_options.save_everystep#
p_Ds_v5 = inputs.p_Ds_v5  # contains model parameters, and the "Es" solver/interpolator#
trdf = inputs.trdf#
root_age = maximum(trdf[!, :node_age])#
#
# Look at the model parameters (Q and C matrix)#
Rcbind(p_Ds_v5.p_indices.Qarray_ivals, p_Ds_v5.p_indices.Qarray_jvals, p_Ds_v5.params.Qij_vals)#
Rcbind(p_Ds_v5.p_indices.Carray_ivals, p_Ds_v5.p_indices.Carray_jvals, p_Ds_v5.p_indices.Carray_kvals, p_Ds_v5.params.Cijk_vals)#
p_Ds_v5.params.mu_vals
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.1#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
res2
tr
plot(tr)
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])
rowSums(base[,4:6)
rowSums(base[,4:6])
lq
rowSums(base[,4:6]) * exp(lq)
base[,4:6] * exp(lq)
base[, 4:6]
exp(lq)
base[,4:6] * t(exp(lq))
base[,4] * exp(lq)#
base[,5] * exp(lq)#
base[,6] * exp(lq)
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.0#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.EQUI, condition.surv=FALSE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
loglik = log(sum(equilibrium_root_freqs * d_root_orig)) + sum(lq)#
loglik#
# -12.269765 matches!#
# If root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
root.p = d_root_orig/sum(d_root_orig)#
lambda <- classe_params[E_indices]#
e.root <- vals[E_indices]#
#
# BiSSE#
#d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
# MuSSE/ClaSSE#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=TRUE#
root.p = rep(1/nstates, times=nstates)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0.25,0.25,0.25,0.25)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=TRUE#
root.p = c(0.1, 0.1, 0.1, 0.7)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0, 0, 0, 1)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik
########################################################
# Compare ClaSSE and BiSSE calculations#
##
# E.g.:#
# diversitree versus plain-R#
# diversitree versus BioGeoBEARS+Yule+BFs#
# #
########################################################
#
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.0#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.EQUI, condition.surv=FALSE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
loglik = log(sum(equilibrium_root_freqs * d_root_orig)) + sum(lq)#
loglik#
# -12.269765 matches!#
# If root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
root.p = d_root_orig/sum(d_root_orig)#
lambda <- classe_params[E_indices]#
e.root <- vals[E_indices]#
#
# BiSSE#
#d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
# MuSSE/ClaSSE#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=TRUE#
root.p = rep(1/nstates, times=nstates)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0.25,0.25,0.25)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=TRUE#
root.p = c(0.1, 0.1, .7)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0, 0, 1)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
# If root=ROOT.EQUI, condition.surv=TRUE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(equilibrium_root_freqs * lambda * (1 - e.root)^2)#
loglik = log(sum(equilibrium_root_freqs * d.root)) + sum(lq)#
loglik#
# -12.94599 matches!#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base
LnLs = rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5)#
print(LnLs)#
#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 4-6, the Ds, sum to 1#
rowSums(base[,4:6])
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
#
rowSums(base[,4:6]) * exp(lq)#
base[,4] * exp(lq)#
base[,5] * exp(lq)#
base[,6] * exp(lq)
classe_params_DEC
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.0#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 2/6 * birthRate#
classe_params[param_names=="lambda321"] = 2/6 * birthRate#
classe_params[param_names=="lambda313"] = 2/6 * birthRate#
classe_params[param_names=="lambda331"] = 2/6 * birthRate#
classe_params[param_names=="lambda323"] = 2/6 * birthRate#
classe_params[param_names=="lambda332"] = 2/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.5)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.EQUI, condition.surv=FALSE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
loglik = log(sum(equilibrium_root_freqs * d_root_orig)) + sum(lq)#
loglik#
# -12.269765 matches!#
# If root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
root.p = d_root_orig/sum(d_root_orig)#
lambda <- classe_params[E_indices]#
e.root <- vals[E_indices]#
#
# BiSSE#
#d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
# MuSSE/ClaSSE#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=TRUE#
root.p = rep(1/nstates, times=nstates)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0.25,0.25,0.25)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=TRUE#
root.p = c(0.1, 0.1, .7)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0, 0, 1)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
# If root=ROOT.EQUI, condition.surv=TRUE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(equilibrium_root_freqs * lambda * (1 - e.root)^2)#
loglik = log(sum(equilibrium_root_freqs * d.root)) + sum(lq)#
loglik#
# -12.94599 matches!#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Get Es,Ds matrix#
Dindexes = (nstates+1):(nstates*2)#
EsDs_branch_bottoms = base#
EsDs_branch_bottoms[,Dindexes] = EsDs_branch_bottoms[,Dindexes] * exp(attr(res2, "intermediates")$lq)#
EsDs_branch_bottoms[1,]#
# Yay! Figured it out!#
#
projection.matrix.classe <- function(pars, k) #
LnLs = rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5)#
print(LnLs)#
#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 4-6, the Ds, sum to 1#
rowSums(base[,4:6])#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
#
rowSums(base[,4:6]) * exp(lq)#
base[,4] * exp(lq)#
base[,5] * exp(lq)#
base[,6] * exp(lq)
classe_params_DEC
########################################################
# Compare ClaSSE and BiSSE calculations#
##
# E.g.:#
# diversitree versus plain-R#
# diversitree versus BioGeoBEARS+Yule+BFs#
# #
########################################################
#
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.0#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 2/6 * birthRate#
classe_params[param_names=="lambda321"] = 2/6 * birthRate#
classe_params[param_names=="lambda313"] = 2/6 * birthRate#
classe_params[param_names=="lambda331"] = 2/6 * birthRate#
classe_params[param_names=="lambda323"] = 2/6 * birthRate#
classe_params[param_names=="lambda332"] = 2/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.3333333)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(1,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.0#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 2/6 * birthRate#
classe_params[param_names=="lambda321"] = 2/6 * birthRate#
classe_params[param_names=="lambda313"] = 2/6 * birthRate#
classe_params[param_names=="lambda331"] = 2/6 * birthRate#
classe_params[param_names=="lambda323"] = 2/6 * birthRate#
classe_params[param_names=="lambda332"] = 2/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.3333333)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(1,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.0#
d_val = 0.01#
e_val = 0.001#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.3333333)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
tr
inputs
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.222222#
deathRate = 0.0#
d_val = 0.0#
e_val = 0.0#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.3333333)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik
exp(-2.615188)
1/exp(-2.615188)
res2t
log(0.222222)
attr(res2, "intermediates")$init
attr(res2, "intermediates")$lq
sum(attr(res2, "intermediates")$lq)
exp(-0.222222)
exp(-0.444444)
exp(-1.726300)
1/exp(-1.726300)
yule(tr)
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.2#
deathRate = 0.0#
d_val = 0.0#
e_val = 0.0#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.3333333)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.EQUI, condition.surv=FALSE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
loglik = log(sum(equilibrium_root_freqs * d_root_orig)) + sum(lq)#
loglik#
# -12.269765 matches!#
# If root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
root.p = d_root_orig/sum(d_root_orig)#
lambda <- classe_params[E_indices]#
e.root <- vals[E_indices]#
#
# BiSSE#
#d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
# MuSSE/ClaSSE#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=TRUE#
root.p = rep(1/nstates, times=nstates)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0.25,0.25,0.25)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=TRUE#
root.p = c(0.1, 0.1, .7)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0, 0, 1)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik
-1.916291--2.609438
exp(0.693147)
-1.916291 + log(-2)
-1.916291 + log(2)
-1.916291 - log(2)
yule(tr)
yule(tr)$loglik
########################################################
# Compare ClaSSE and BiSSE calculations#
##
# E.g.:#
# diversitree versus plain-R#
# diversitree versus BioGeoBEARS+Yule+BFs#
# #
########################################################
#
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.2#
deathRate = 0.0#
d_val = 0.0#
e_val = 0.0#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25,0.25,0.25)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.7)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25,0.25,0.25)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.7)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - log(0.3333333)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
# Key parts of the calculation#
lq = t(attr(res2, "intermediates")$lq)			# Branch likelihoods#
vals = t(attr(res2, "intermediates")$vals)	# Es and Ds at the root#
nstates = length(vals) / 2#
E_indices = 1:nstates#
d_root_orig = vals[-E_indices]							# Original D likelihoods at root#
#
# If root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
root.p = d_root_orig/sum(d_root_orig)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=FALSE#
root.p = rep(1/nstates, times=nstates)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0.25,0.25, 0.25)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=FALSE#
root.p = c(0.1, 0.1, 0.7)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=FALSE#
root.p = c(0, 0, 1)#
loglik = log(sum(root.p * d_root_orig)) + sum(lq)#
loglik#
#
# If root=ROOT.EQUI, condition.surv=FALSE#
#
# Project the ClaSSE model onto an instantaneous rate matrix, A#
A = projection.matrix.classe(pars=classe_params, k) #
#
# Calculate equilibrium frequencies by eigenvectors#
evA <- eigen(A)#
i <- which(evA$values == max(evA$values))#
equilibrium_root_freqs = evA$vectors[, i]/sum(evA$vectors[, i])#
equilibrium_root_freqs#
# 0.2652666 0.2285983 0.2285983 0.2775368#
#
loglik = log(sum(equilibrium_root_freqs * d_root_orig)) + sum(lq)#
loglik#
# -12.269765 matches!#
# If root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
root.p = d_root_orig/sum(d_root_orig)#
lambda <- classe_params[E_indices]#
e.root <- vals[E_indices]#
#
# BiSSE#
#d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
# MuSSE/ClaSSE#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.FLAT, root.p=NULL, condition.surv=TRUE#
root.p = rep(1/nstates, times=nstates)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0.25,0.25,0.25)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.75,0.25), condition.surv=TRUE#
root.p = c(0.1, 0.1, .7)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
#
# If root=ROOT.GIVEN, root.p=c(0.5,0.5), condition.surv=TRUE#
root.p = c(0, 0, 1)#
pars = classe_params#
nsum <- k * (k + 1)/2#
lambda <- colSums(matrix(pars[1:(nsum * k)], nrow = nsum))#
i <- seq_len(k)#
e.root <- vals[i]#
d.root <- d_root_orig/sum(root.p * lambda * (1 - e.root)^2)#
loglik = log(sum(root.p * d.root)) + sum(lq)#
loglik#
yule(tr)$loglik + log(-2)
yule(tr)$loglik - log(2)
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
#
yule(tr)$loglik - log(2)
res2t
attr(,"intermediates")$lq
attr(res2t,"intermediates")$lq
exp(attr(res2t,"intermediates")$lq)
sum(exp(attr(res2t,"intermediates")$lq))
sum(attr(res2t,"intermediates")$lq)
Ldiff = exp((LnLst$ttl_LnL - log(birthRate)) - LnLst$branch_LnL)#
LnLst2 = cbind(LnLst, Ldiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
Ldiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLdiff = (LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate))#
LnLst2 = cbind(LnLst, Ldiff, LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
res1
get_classe_LnLs
res
res =res1
res
attr(res,"intermediates")$init
init = attr(res,"intermediates")$init#
#
	# Branch bottom values ("base")#
	base = attr(res,"intermediates")$base#
#
	numstates = nrow(init) / 2#
	numnodes = ncol(init) # internal plus tip nodes#
	numTips = (ncol(init) + 1) / 2#
	numInternal = numTips - 1
zeros
matrix()
init
t(init)
init = attr(res,"intermediates")$init#
	# Branch bottom values ("base")#
	base = attr(res,"intermediates")$base#
#
	# Assumes bifurcating tree#
	numstates = nrow(init) / 2#
	numnodes = ncol(init) # internal plus tip nodes#
	numTips = (ncol(init) + 1) / 2#
	numInternal = numTips - 1#
	Es_atNode_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	Es_atNode_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes) #
	likes_at_each_nodeIndex_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	likes_at_each_nodeIndex_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes) #
	normlikes_at_each_nodeIndex_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	normlikes_at_each_nodeIndex_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes)#
	Ecols = 1:numstates#
	Dcols = (numstates+1):(2*numstates)#
	Es_atNode_branchTop = (t(init))[,Ecols]#
	Es_atNode_branchBot = (t(base))[,Ecols]#
	likes_at_each_nodeIndex_branchTop = (t(init))[,Dcols]#
	likes_at_each_nodeIndex_branchBot = (t(base))[,Dcols]#
	Es_atNode_branchTop#
	Es_atNode_branchBot#
	likes_at_each_nodeIndex_branchTop#
	likes_at_each_nodeIndex_branchBot
res
attr(res,"intermediates")$lq
exp(attr(res,"intermediates")$lq)
# Branch top values ("initial")#
	init = attr(res,"intermediates")$init#
	# Branch bottom values ("base")#
	base = attr(res,"intermediates")$base#
	# lqs = log-likelihoods at each branch bottom#
	lq = attr(res,"intermediates")$lq#
	q = exp(attr(res,"intermediates")$lq)#
	# Assumes bifurcating tree#
	numstates = nrow(init) / 2#
	numnodes = ncol(init) # internal plus tip nodes#
	numTips = (ncol(init) + 1) / 2#
	numInternal = numTips - 1#
	Es_atNode_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	Es_atNode_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes) #
	likes_at_each_nodeIndex_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	likes_at_each_nodeIndex_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes) #
	normlikes_at_each_nodeIndex_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	normlikes_at_each_nodeIndex_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes)#
	Ecols = 1:numstates#
	Dcols = (numstates+1):(2*numstates)#
	Es_atNode_branchTop = (t(init))[,Ecols]#
	Es_atNode_branchBot = (t(base))[,Ecols]#
	likes_at_each_nodeIndex_branchTop = (t(init))[,Dcols]#
	normlikes_at_each_nodeIndex_branchBot = (t(base))[,Dcols]#
	normlikes_at_each_nodeIndex_branchTop = likes_at_each_nodeIndex_branchTop / rowSums(likes_at_each_nodeIndex_branchTop)#
	likes_at_each_nodeIndex_branchBot = normlikes_at_each_nodeIndex_branchBot / q#
	Es_atNode_branchTop#
	Es_atNode_branchBot#
	likes_at_each_nodeIndex_branchTop#
	likes_at_each_nodeIndex_branchBot#
	normlikes_at_each_nodeIndex_branchBot#
	normlikes_at_each_nodeIndex_branchTop
(t(init))[,Dcols]
q
(t(base))[,Dcols]
# Branch top values ("initial")#
	init = attr(res,"intermediates")$init#
	# Branch bottom values ("base")#
	base = attr(res,"intermediates")$base#
	# lqs = log-likelihoods at each branch bottom#
	lq = attr(res,"intermediates")$lq#
	q = exp(attr(res,"intermediates")$lq)#
	# Assumes bifurcating tree#
	numstates = nrow(init) / 2#
	numnodes = ncol(init) # internal plus tip nodes#
	numTips = (ncol(init) + 1) / 2#
	numInternal = numTips - 1#
	Es_atNode_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	Es_atNode_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes) #
	likes_at_each_nodeIndex_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	likes_at_each_nodeIndex_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes) #
	normlikes_at_each_nodeIndex_branchTop = matrix(data=0, ncol=numstates, nrow=numnodes)#
	normlikes_at_each_nodeIndex_branchBot = matrix(data=0, ncol=numstates, nrow=numnodes)#
	Ecols = 1:numstates#
	Dcols = (numstates+1):(2*numstates)#
	Es_atNode_branchTop = (t(init))[,Ecols]#
	Es_atNode_branchBot = (t(base))[,Ecols]#
	likes_at_each_nodeIndex_branchTop = (t(init))[,Dcols]#
	normlikes_at_each_nodeIndex_branchBot = (t(base))[,Dcols]#
	normlikes_at_each_nodeIndex_branchTop = likes_at_each_nodeIndex_branchTop / rowSums(likes_at_each_nodeIndex_branchTop)#
	likes_at_each_nodeIndex_branchBot = normlikes_at_each_nodeIndex_branchBot * q#
	Es_atNode_branchTop#
	Es_atNode_branchBot#
	likes_at_each_nodeIndex_branchTop#
	likes_at_each_nodeIndex_branchBot#
	normlikes_at_each_nodeIndex_branchBot#
	normlikes_at_each_nodeIndex_branchTop#
	}
q
lq
res
q
lq
ROOT.OBS
ROOT.GIVEN
class(ROOT.OBS)
ROOT.FLAT
ROOT.EQUI
root.p = d_root_orig/sum(d_root_orig)#
lambda <- classe_params[E_indices]#
e.root <- vals[E_indices]
e.root
lambdia
lambda
classe_params
ROOT.ALL
\
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.8)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.8)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
LikDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLdiff = (LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate))#
LnLst2 = cbind(LnLst, Ldiff, LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
log(5)
1/5
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
LikDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
LnLst2 = cbind(LnLst, Ldiff, LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
LikDiff
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.8)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.8)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
LikDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
LnLst2 = cbind(LnLst, Ldiff, LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.8)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.8)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
LikDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
LnLst2 = cbind(LnLst, LikDiff, LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
likes_at_each_nodeIndex_branchTop
log(likes_at_each_nodeIndex_branchTop)
-1.609438*2
-1.609438*2+log(0.2)
Es_atNode_branchTop#
	Es_atNode_branchBot#
	likes_at_each_nodeIndex_branchTop#
	likes_at_each_nodeIndex_branchBot#
	normlikes_at_each_nodeIndex_branchTop#
	normlikes_at_each_nodeIndex_branchBot
rowSums(likes_at_each_nodeIndex_branchBot)
log(rowSums(likes_at_each_nodeIndex_branchBot))
0.8187308*0.8187308
trtable
tr
trtable = prt(tr, printflag=FALSE)
init
t(init)
t(init) ( vals)
t(init) *( vals)
vals
t(init) *t( vals)
t(init) * vals
vals
lq
q
likes_at_each_nodeIndex_branchBot
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_pureR_v1.R") # simple implementations in plain-R#
# Load simple example tree#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
trfn = "tree_small.newick"#
tr = read.tree(trfn)#
#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
#
# Run a BiSSE model from diversitree#
#
# Setup#
states = c(2,2,2)		# Tip states#
names(states) = tr$tip.label#
states#
#
sampling.f = c(1,1,1)		# Proportion of species in each state; for 2 states#
											# (Let's assume we have all species)#
k = length(sampling.f)#
#
# Create the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_3states = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# Input some parameters#
birthRate = 0.2#
deathRate = 0.1#
d_val = 0.0#
e_val = 0.0#
j_val = 0.0#
#
# The names of the parameters:#
param_names = argnames(classe_3states)#
param_names#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
# This is basically a DEC model for 4 states#
#
# All extinction rates are the same (state-independent)#
# Here, deathRate is 0 for all states#
#classe_params[grepl(pattern="lambda", x=param_names)] = birthRate#
classe_params[grepl(pattern="mu", x=param_names)] = deathRate#
classe_params[grepl(pattern="q", x=param_names)] = 0#
#
# For DEC#
classe_params[param_names == "q31"] = e_val#
classe_params[param_names == "q32"] = e_val#
classe_params[param_names == "q13"] = d_val#
classe_params[param_names == "q23"] = d_val#
classe_params#
# The birthRate (lambda) is state-independent.  However, #
# only certain cladogenesis scenarios are allowed under DEC.#
##
# Disallowed cladogenesis scenarios have a rate of 0.#
##
# If there is more than one cladogenesis scenario conditional #
# on a certain ancestor, DEC assigns each a weight of 1, and #
# then divides by the sum of the weights. I.e., if there are#
# six possible cladogenetic range-inheritance events, they #
# each get a conditional probability of 1/6.#
# #
# To translate to ClaSSE, if the speciation rate for a lineage #
# in a certain state is lambda, then the rate of each individual #
# allowed scenario would be lambda * 1/6#
# #
y_val = (3-j_val)/3#
total_of_weights = y_val + j_val + j_val#
yprob = y_val / total_of_weights#
jprob = j_val / total_of_weights#
# Specifying the nonzero lambdas#
# Narrow sympatry (ancestor A or B; rangesize of 1 area)#
classe_params[param_names=="lambda111"] = birthRate#
classe_params[param_names=="lambda222"] = yprob * birthRate#
classe_params[param_names=="lambda333"] = 0#
#
# Jump dispersal speciation#
classe_params[param_names=="lambda112"] = jprob * birthRate#
classe_params[param_names=="lambda121"] = jprob * birthRate#
classe_params[param_names=="lambda212"] = jprob * birthRate#
classe_params[param_names=="lambda221"] = jprob * birthRate#
#
# Subset sympatry for state AB#
classe_params[param_names=="lambda312"] = 1/6 * birthRate#
classe_params[param_names=="lambda321"] = 1/6 * birthRate#
classe_params[param_names=="lambda313"] = 1/6 * birthRate#
classe_params[param_names=="lambda331"] = 1/6 * birthRate#
classe_params[param_names=="lambda323"] = 1/6 * birthRate#
classe_params[param_names=="lambda332"] = 1/6 * birthRate#
#
classe_params_DEC = classe_params#
# To see the function:#
dput(classe_3states)#
#
classe_3states_default <- function(pars, condition.surv=TRUE, root=ROOT.OBS, root.p=NULL, intermediates=FALSE) #
	{#
	## Note that this uses MuSSE's cache...#
	pars2 <- f.pars(pars)#
	ans <- all.branches(pars2, intermediates)#
	ans$branchLnL = sum(ans$lq)#
	rootfunc.classe(ans, pars, condition.surv, root, root.p, intermediates)#
	}#
# Do the ClaSSE calculation, under many different assumptions#
res1 = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.1, 0.1, 0.8)#
res4 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 0, 1)#
res5 = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_3states(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_3states(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.3333333, 0.3333333, 0.3333333)#
res3t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.1, 0.1, 0.8)#
res4t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 0, 1)#
res5t = classe_3states(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_3states(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
LikDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
LnLst2 = cbind(LnLst, LikDiff, LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
LnLst
