sum(log(computed_likelihoods_at_each_node))
sum(log(computed_likelihoods_at_each_node_x_lambda)) - 2*log(0.2222222)
computed_likelihoods_at_each_node
sum(log(computed_likelihoods_at_each_node_x_lambda)) - 2*log(0.2222222)
sum(log(computed_likelihoods_at_each_node))
rootstates_lnL
LnLs1
?make.bisse
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 0, 0) # 3 states for 3 tips#
states = c(1, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)
bisse_2areas
fit.mle()
find.mle()
?find.mle()
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 0, 0) # 3 states for 3 tips#
states = c(1, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.1#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.1#
q10 = 0.1#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
fit <- find.mle(lik=bisse_2areas, x.init=bisse_params, method="subplex")
fit <- find.mle(func=bisse_2areas, x.init=bisse_params, method="subplex")
?constraint
?constrain
constrain(func=bisse_2areas, lambda0~lambda1, mu0=0.0, mu1=0.0, q01=1.0, q10=1.0)
constraints = list(lambda0~lambda1, mu0~0.0, mu1~0.0, q01~1.0, q10~1.0)#
constrain(func=bisse_2areas, formulae=constraints)
constrain(f=bisse_2areas, formulae=constraints)
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.0#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.0#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
constraints = list(lambda0~lambda1, mu0~0.0, mu1~0.0, q01~1.0, q10~1.0)#
constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 10 seconds#
fit <- find.mle(func=bisse_2areas, x.init=bisse_params, method="subplex")
fit
bisse_params
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 10 seconds#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")
fit
constraints = list(lambda0~lambda1, mu0~0.0, mu1~0.0, q01~0.0, q10~0.0)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 10 seconds#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")
fit
tr
yule(tr)
names(fit)
fit$par
fit$par.full
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
#
# Compare to Yule#
yule(tr)#
#
bisse_params_orig = bisse_params#
bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
yule(tr)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)
yule(tr)#
#
bisse_params_orig = bisse_params#
bisse_params = fit$par.full
names(fit)
fit$lnLik
?find.mle
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", root=ROOT.OBS, root.p=NULL, condition.surv=FALSE)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", root=ROOT.OBS)
defaults = list(root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", defaults=defaults)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", condition.surv=FALSE)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, condition.surv=FALSE)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, list(condition.surv=FALSE))
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", list(condition.surv=FALSE))
fit
defaults = list(root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", defaults)
defaults = list(root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex", list(root=ROOT.OBS), list(condition.surv=FALSE))
fit
bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
bisse_2areas_constrained2 = bisse_2areas_constrained(root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)
bisse_2areas_constrained2 = bisse_2areas_constrained(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)
bisse_params
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params[1], method="subplex")
fit$logLike
fit$logLik
names(fit)
fit$lnLik
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params[1], method="subplex", condition.surv=FALSE)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params[1], method="subplex")#
fit$par.full#
fit$lnLik
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.0#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.0#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
constraints = list(lambda0~lambda1, mu0~0.0, mu1~0.0, q01~0.0, q10~0.0)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 1 seconds#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params[1], method="subplex")#
fit$par.full#
fit$lnLik#
#
# Compare to Yule#
yule(tr)#
#
bisse_params_orig = bisse_params#
bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
bisse_params
bisse_params$lambda0
bisse_params["lambda0"]
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)
lq#
sum(lq)
LnLs1t
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
bisse_params
yule(tr)
yule(tr)$loglik
yule(tr)$loglik + -2.609438
-5.828748 - v
-5.828748 - -4.525729
exp(-1.303019#
)
log(0.2)
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 0, 0) # 3 states for 3 tips#
states = c(1, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.0#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.0#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 1 seconds#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params[1], method="subplex")#
fit$par.full#
fit$lnLik
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 0, 0) # 3 states for 3 tips#
states = c(1, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.1#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.1#
q10 = 0.1#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params[1], method="subplex")#
fit$par.full
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
fit$par.full#
fit$lnLik
states = c(0, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.1#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.1#
q10 = 0.1#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 1 seconds#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
fit$par.full#
fit$lnLik
yule(tr)#
#
bisse_params_orig = bisse_params#
bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
########################################################
########################################################
# 5. BiSSE likelihoods and comparison to yule#
########################################################
########################################################
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# [1] -0.1999566 -0.1999566 -0.3999132         NA -1.8096115#
sum(lnls, na.rm=TRUE)
sum(log(computed_likelihoods_at_each_node_x_lambda))
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.1#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.1#
q10 = 0.1#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 1 seconds#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
fit$par.full#
fit$lnLik#
#
# Compare to Yule#
yule(tr)#
#
bisse_params_orig = bisse_params#
bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
########################################################
########################################################
# 5. BiSSE likelihoods and comparison to yule#
########################################################
########################################################
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
# condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#              [,1]         [,2]       [,3]       [,4]#
# [1,] 0.000000e+00 0.000000e+00 1.00000000 0.00000000#
# [2,] 0.000000e+00 0.000000e+00 0.00000000 1.00000000#
# [3,] 0.000000e+00 0.000000e+00 0.00000000 1.00000000#
# [4,] 1.488113e-13 1.488113e-13 0.05000001 0.05000002#
# [5,] 8.182151e-14 8.182151e-14 0.05000002 0.05000002#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#      [,1] [,2] [,3]      [,4]#
# [1,]    0    0    0 1.0000000#
# [2,]    0    0    0 1.0000000#
# [3,]    0    0    0 1.0000000#
# [4,]    0    0    0 0.2000001#
# [5,]    0    0    0 0.2000001#
# Matches matches diversitree BiSSE "base" -- but a weird combination of #
# - left columns: average E's passed down#
# - right columns: normalized conditional likelihoods#
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#              [,1]         [,2] [,3] [,4]#
# [1,] 8.182151e-14 8.182151e-14  0.5  0.5#
# [2,] 8.182151e-14 8.182151e-14  0.5  0.5#
# [3,] 1.488113e-13 1.488113e-13  0.5  0.5#
# [4,]           NA           NA   NA   NA#
# [5,] 1.488113e-13 1.488113e-13  0.5  0.5#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#      [,1] [,2] [,3] [,4]#
# [1,]    0    0    0    1#
# [2,]    0    0    0    1#
# [3,]    0    0    0    1#
# [4,]    0    0    0    0#
# [5,]    0    0    0    1#
#
# lq and likelihoods#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#      [,1] [,2] [,3]      [,4]#
# [1,]    0    0    0 0.8187307#
# [2,]    0    0    0 0.8187307#
# [3,]    0    0    0 0.6703200#
# [4,]    0    0    0 0.0000000#
# [5,]    0    0    0 0.1637462#
#
# Matches diversitree BiSSE "lq"#
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# -0.2000001 -0.2000001 -0.4000001         NA -1.8094377#
sum(lnls, na.rm=TRUE)#
# [1] -2.609438#
# Sum of the branch likelihoods#
lq#
sum(lq)#
# -0.1999566 -0.1999566 -0.3999132  0.0000000 -1.8096115#
# [1] -2.609438#
#
# Add the root probabilities#
# Assuming diversitree options:#
# root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
# i.e., the root state probs are just the root_Ds/sum(root_Ds)#
LnLs1t#
# -2.609438 -2.609438#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))#
# -5.828748#
R_result_branch_lnL = -2.609438#
R_result_total_lnL = -2.609438#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -5.828748#
########################################################
########################################################
# END PROOF OF MATCHING
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
lq
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)
lq#
sum(lq)
LnLs1t
LnLs1
bisse_params
bisse_params["q10"]
sum(log(computed_likelihoods_at_each_node_x_lambda))
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 1.2#
#
lambda0 = birthRate*2#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate*2#
q01 = 0.4#
q10 = 0.2#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
# constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
# bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
# #
# Wait 1 seconds#
# fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
# fit$par.full#
# fit$lnLik#
# #
# Compare to Yule#
# yule(tr)#
# #
# bisse_params_orig = bisse_params#
# bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
########################################################
########################################################
# 5. BiSSE likelihoods and comparison to yule#
########################################################
########################################################
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
# condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#              [,1]         [,2]       [,3]       [,4]#
# [1,] 0.000000e+00 0.000000e+00 1.00000000 0.00000000#
# [2,] 0.000000e+00 0.000000e+00 0.00000000 1.00000000#
# [3,] 0.000000e+00 0.000000e+00 0.00000000 1.00000000#
# [4,] 1.488113e-13 1.488113e-13 0.05000001 0.05000002#
# [5,] 8.182151e-14 8.182151e-14 0.05000002 0.05000002#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#      [,1] [,2] [,3]      [,4]#
# [1,]    0    0    0 1.0000000#
# [2,]    0    0    0 1.0000000#
# [3,]    0    0    0 1.0000000#
# [4,]    0    0    0 0.2000001#
# [5,]    0    0    0 0.2000001#
# Matches matches diversitree BiSSE "base" -- but a weird combination of #
# - left columns: average E's passed down#
# - right columns: normalized conditional likelihoods#
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#              [,1]         [,2] [,3] [,4]#
# [1,] 8.182151e-14 8.182151e-14  0.5  0.5#
# [2,] 8.182151e-14 8.182151e-14  0.5  0.5#
# [3,] 1.488113e-13 1.488113e-13  0.5  0.5#
# [4,]           NA           NA   NA   NA#
# [5,] 1.488113e-13 1.488113e-13  0.5  0.5#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#      [,1] [,2] [,3] [,4]#
# [1,]    0    0    0    1#
# [2,]    0    0    0    1#
# [3,]    0    0    0    1#
# [4,]    0    0    0    0#
# [5,]    0    0    0    1#
#
# lq and likelihoods#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#      [,1] [,2] [,3]      [,4]#
# [1,]    0    0    0 0.8187307#
# [2,]    0    0    0 0.8187307#
# [3,]    0    0    0 0.6703200#
# [4,]    0    0    0 0.0000000#
# [5,]    0    0    0 0.1637462#
#
# Matches diversitree BiSSE "lq"#
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# -0.2000001 -0.2000001 -0.4000002         NA -2.5025850#
sum(lnls, na.rm=TRUE)#
# [1] -3.302585#
# Sum of the branch likelihoods#
lq#
sum(lq)#
# -0.1999566 -0.1999566 -0.3999132  0.0000000 -1.8096115#
# -3.302585#
#
# Add the root probabilities#
# Assuming diversitree options:#
# root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
# i.e., the root state probs are just the root_Ds/sum(root_Ds)#
LnLs1#
# -6.298317 -3.302585#
#
# root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
LnLs1t#
# -4.688879 -3.302585#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda#
# -7.907755#
R_result_branch_lnL = -3.302585#
R_result_total_LnLs1 = -6.298317#
R_result_total_LnLs1t = -4.688879#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -7.907755#
########################################################
########################################################
# END PROOF OF MATCHING
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 0, 0) # 3 states for 3 tips#
states = c(1, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.0#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.0#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
constraints = list(lambda0~lambda1, mu0~0.0, mu1~0.0, q01~0.0, q10~0.0)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
#
# Wait 1 seconds#
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
fit$par.full#
fit$lnLik#
#
# Compare to Yule#
yule(tr)#
#
bisse_params_orig = bisse_params#
bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
########################################################
########################################################
# 5. BiSSE likelihoods and comparison to yule#
########################################################
########################################################
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#      [,1] [,2] [,3]      [,4]#
# [1,]    0    0    0 1.0000000#
# [2,]    0    0    0 1.0000000#
# [3,]    0    0    0 1.0000000#
# [4,]    0    0    0 0.1999566#
# [5,]    0    0    0 0.1999566#
# > condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#      [,1] [,2] [,3]      [,4]#
# [1,]    0    0    0 1.0000000#
# [2,]    0    0    0 1.0000000#
# [3,]    0    0    0 1.0000000#
# [4,]    0    0    0 0.1999566#
# [5,]    0    0    0 0.1999566#
# Matches matches diversitree BiSSE "base" -- but a weird combination of #
# - left columns: average E's passed down#
# - right columns: normalized conditional likelihoods#
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#      [,1] [,2] [,3] [,4]#
# [1,]    0    0    0    1#
# [2,]    0    0    0    1#
# [3,]    0    0    0    1#
# [4,]   NA   NA   NA   NA#
# [5,]    0    0    0    1#
# > condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#      [,1] [,2] [,3] [,4]#
# [1,]    0    0    0    1#
# [2,]    0    0    0    1#
# [3,]    0    0    0    1#
# [4,]    0    0    0    0#
# [5,]    0    0    0    1#
#
# lq and likelihoods#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#      [,1] [,2] [,3]      [,4]#
# [1,]    0    0    0 0.8187663#
# [2,]    0    0    0 0.8187663#
# [3,]    0    0    0 0.6703782#
# [4,]    0    0    0 0.0000000#
# [5,]    0    0    0 0.1637177#
#
# Matches diversitree BiSSE "lq"#
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# [1] -0.1999566 -0.1999566 -0.3999132         NA -1.8096115#
sum(lnls, na.rm=TRUE)#
# [1] -2.609438#
# Sum of the branch likelihoods#
lq#
sum(lq)#
# -0.1999566 -0.1999566 -0.3999132  0.0000000 -1.8096115#
# [1] -2.609438#
#
# Add the root probabilities#
# Assuming diversitree options:#
# root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
# i.e., the root state probs are just the root_Ds/sum(root_Ds)#
LnLs1t#
# -2.609438 -2.609438#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))#
# -5.828748#
R_result_branch_lnL = -2.609438#
R_result_total_lnL = -2.609438#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -5.828748#
########################################################
########################################################
# END PROOF OF MATCHING
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}
SPCmod
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms)
out
plot(times, out$P)
plot(times, out["P"])
plot(times, out[,"P"])
points(times, out[,"C"], col="blue")
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")
states = c(1, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states
states = c(0, 0, 0) # 3 binary states for 3 tips#
states = c(1, 1, 1) # 3 binary states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 0.0#
#
lambda0 = birthRate#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate#
q01 = 0.0#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms
constraints = list(lambda0~lambda1, mu0~0.0, mu1~0.0, q01~0.0, q10~0.0)#
bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")
fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
fit$par.full#
fit$lnLik
yule(tr)
bisse_params_orig = bisse_params#
bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)
base[,34]
base[,3:4]
base[,3:4] * lq
exp(base[,3:4] * lq)
0.2 * 0.8187663
lq
sum(lq)
log(0.5)
log(0.5)+sum(lq)
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result
t
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=2, y=y, parms=parms)#
one_step_result
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out
lq
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)
condlikes_of_each_treeState_BRANCHTOP_AT_NODE
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE
condlikes_of_each_treeState_BRANCHTOP_AT_NODE
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])
relative_probs_of_each_state_BRANCHTOP_AT_NODE
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)
computed_likelihoods_at_each_node
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node
computed_likelihoods_at_each_node
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node
computed_likelihoods_at_each_node_x_lambda
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1
edges_to_visit
tr
names(tr)
tr$edge
prt(tr)
edges_to_visit
tr
tr$edge
tr2$edge
tr$edge.length
init
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = 0#
mu1 = 0#
# Character transition#
q01 = 0.0 # ML#
q10 = 0.0#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# [1] -0.1999566 -0.1999566 -0.3999132         NA -1.8096115#
sum(lnls, na.rm=TRUE)#
# [1] -2.609438#
# Sum of the branch likelihoods#
lq#
sum(lq)
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
base[,3:4] * lq#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
base[,3:4] * exp(lq)#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]
rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4])
log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)
lq#
sum(lq)
LnLs1t#
# -2.609438 -2.609438#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 1.2#
#
lambda0 = birthRate*2#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate*2#
q01 = 0.4#
q10 = 0.2#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
# constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
# bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
# #
# Wait 1 seconds#
# fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
# fit$par.full#
# fit$lnLik#
# #
# Compare to Yule#
# yule(tr)#
# #
# bisse_params_orig = bisse_params#
# bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
########################################################
########################################################
# 5. BiSSE likelihoods and comparison to yule#
########################################################
########################################################
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
#           [,1]      [,2]      [,3]        [,4]#
# [1,] 0.0000000 0.0000000 1.0000000 0.000000000#
# [2,] 0.0000000 0.0000000 0.0000000 1.000000000#
# [3,] 0.0000000 0.0000000 0.0000000 1.000000000#
# [4,] 0.8988459 0.9775416 0.2597286 0.009541766#
# [5,] 0.6888798 0.8799765 0.1518462 0.015528271#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#           [,1]      [,2]       [,3]       [,4]#
# [1,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [2,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [3,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [4,] 0.8988459 0.9775416 0.20907825 0.02186927#
# [5,] 0.6888798 0.8799766 0.06604511 0.08391649#
# Matches matches diversitree BiSSE "base" -- but a weird combination of #
# - left columns: average E's passed down#
# - right columns: normalized conditional likelihoods#
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]      [,3]      [,4]#
# [1,] 0.6888798 0.8799765 0.8862882 0.1137118#
# [2,] 0.6888798 0.8799765 0.3854885 0.6145115#
# [3,] 0.8988459 0.9775416 0.6725996 0.3274004#
# [4,]        NA        NA        NA        NA#
# [5,] 0.8988459 0.9775416 0.8688519 0.1311481#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]      [,3]      [,4]#
# [1,] 0.6888798 0.8799766 0.3854886 0.6145114#
# [2,] 0.6888798 0.8799766 0.3854886 0.6145114#
# [3,] 0.8988459 0.9775416 0.6725994 0.3274006#
# [4,] 0.0000000 0.0000000 0.0000000 0.0000000#
# [5,] 0.8988459 0.9775416 0.6994149 0.3005851#
# lq and likelihoods#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]       [,3]        [,4]#
# [1,] 0.6888798 0.8799766 0.05141641 0.081963417#
# [2,] 0.6888798 0.8799766 0.05141641 0.081963417#
# [3,] 0.8988459 0.9775416 0.01959357 0.009537547#
# [4,] 0.0000000 0.0000000 0.00000000 0.000000000#
# [5,] 0.8988459 0.9775416 0.02373981 0.010202572#
#
# Matches diversitree BiSSE "lq"#
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# -1.526391 -2.014554 -3.535949  0.000000 -3.012482#
sum(lnls, na.rm=TRUE)#
# -10.08938#
# Sum of the branch likelihoods#
lq#
sum(lq)#
# -1.526391 -2.014554 -3.535949  0.000000 -3.012482#
# -10.08938#
#
# Add the root probabilities#
# Assuming diversitree options:#
# root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
# i.e., the root state probs are just the root_Ds/sum(root_Ds)#
LnLs1#
# -11.47222 -10.08938#
#
# root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
LnLs1t#
# -6.043899 -10.089376#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
log(computed_likelihoods_at_each_node_x_lambda)
computed_likelihoods_at_each_node_x_lambda
parms
exp(-3.3629410089543565)
computed_likelihoods_at_each_node_x_lambda
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS
c(lambda0, lambda1) * D_relprobs_multiplied
-3.3629410089543565 - -3.0995610530035504
x = -3.3629410089543565 - -3.0995610530035504
exp(x)
root_stateprobs
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 1.2#
#
lambda0 = birthRate*2#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate*2#
q01 = 0.4#
q10 = 0.2#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
# constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
# bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
# #
# Wait 1 seconds#
# fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
# fit$par.full#
# fit$lnLik#
# #
# Compare to Yule#
# yule(tr)#
# #
# bisse_params_orig = bisse_params#
# bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
########################################################
########################################################
# 5. BiSSE likelihoods and comparison to yule#
########################################################
########################################################
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,numstates] = 2	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
#           [,1]      [,2]      [,3]        [,4]#
# [1,] 0.0000000 0.0000000 1.0000000 0.000000000#
# [2,] 0.0000000 0.0000000 0.0000000 1.000000000#
# [3,] 0.0000000 0.0000000 0.0000000 1.000000000#
# [4,] 0.8988459 0.9775416 0.2597286 0.009541766#
# [5,] 0.6888798 0.8799765 0.1518462 0.015528271#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#           [,1]      [,2]       [,3]       [,4]#
# [1,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [2,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [3,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [4,] 0.8988459 0.9775416 0.20907825 0.02186927#
# [5,] 0.6888798 0.8799766 0.06604511 0.08391649#
# Matches matches diversitree BiSSE "base" -- but a weird combination of #
# - left columns: average E's passed down#
# - right columns: normalized conditional likelihoods#
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]      [,3]      [,4]#
# [1,] 0.6888798 0.8799765 0.8862882 0.1137118#
# [2,] 0.6888798 0.8799765 0.3854885 0.6145115#
# [3,] 0.8988459 0.9775416 0.6725996 0.3274004#
# [4,]        NA        NA        NA        NA#
# [5,] 0.8988459 0.9775416 0.8688519 0.1311481#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]      [,3]      [,4]#
# [1,] 0.6888798 0.8799766 0.3854886 0.6145114#
# [2,] 0.6888798 0.8799766 0.3854886 0.6145114#
# [3,] 0.8988459 0.9775416 0.6725994 0.3274006#
# [4,] 0.0000000 0.0000000 0.0000000 0.0000000#
# [5,] 0.8988459 0.9775416 0.6994149 0.3005851#
# lq and likelihoods#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]       [,3]        [,4]#
# [1,] 0.6888798 0.8799766 0.05141641 0.081963417#
# [2,] 0.6888798 0.8799766 0.05141641 0.081963417#
# [3,] 0.8988459 0.9775416 0.01959357 0.009537547#
# [4,] 0.0000000 0.0000000 0.00000000 0.000000000#
# [5,] 0.8988459 0.9775416 0.02373981 0.010202572#
#
# Matches diversitree BiSSE "lq"#
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# -1.526391 -2.014554 -3.535949  0.000000 -3.012482#
sum(lnls, na.rm=TRUE)#
# -10.08938#
# Sum of the branch likelihoods#
lq#
sum(lq)#
# -1.526391 -2.014554 -3.535949  0.000000 -3.012482#
# -10.08938#
#
# Add the root probabilities#
# Assuming diversitree options:#
# root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
# i.e., the root state probs are just the root_Ds/sum(root_Ds)#
LnLs1#
# -11.47222 -10.08938#
#
# root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
LnLs1t#
# -6.043899 -10.089376#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda#
# -14.31109#
R_result_branch_lnL = -10.08938#
R_result_total_LnLs1 = -11.47222#
R_result_total_LnLs1t = -6.043899#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -14.31109#
########################################################
########################################################
# END PROOF OF MATCHING
########################################################
# #
# This script demonstrates how BiSSE is calculated#
# #
########################################################
########################################################
# OUTLINE#
# #
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
##
# 2. Calculation of tree likelihood under a Yule process#
# #
# 3. Set up of equivalent BiSSE model#
##
# 4. BiSSE likelihoods and comparison to DEC#
# #
########################################################
#
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
# plot(tr)#
# axisPhylo()#
# title("Tree with 3 taxa")#
########################################################
########################################################
# 1. Calculation of tip state likelihoods under DEC, in #
#    BioGeoBEARS#
########################################################
########################################################
library(diversitree)#
library(deSolve)		# for lsoda#
#
# After installation, load the package, dependencies, updates#
library(optimx)#
library(FD)#
library(snow)#
library(parallel)#
library(BioGeoBEARS)#
########################################################
# BiSSE directly, using lsoda#
########################################################
#
########################################################
# Example lsoda run#
########################################################
#
# Define the function#
#
# INPUTS#
# t = current time point in integration#
# y = current estimate of the variables in the system#
#     (if names(y) exists, those variables will be available)#
# parms = parameters (named)#
##
# OUTPUTS:#
# The return value of func should be a list, whose first element #
# is a vector containing the derivatives of y with respect to time, #
# and whose next elements are global values that are required at each #
# point in times. The derivatives must be specified in the same order #
# as the state variables y.#
# #
SPCmod <- function(t, x, parms)#
	{#
	with(data=#
	as.list(c(parms, x)), #
		{ # expr#
		import <- sigimp(t)#
		dS <- import - b*S*P + g*C     # substrate#
		dP <- c*S*P  - d*C*P           # producer#
		dC <- e*P*C  - f*C             # consumer#
		res <- c(dS, dP, dC)#
		list(res)#
		}#
	)#
	}#
#
## Parameters #
parms  <- c(b = 0.0, c = 0.1, d = 0.1, e = 0.1, f = 0.1, g = 0.0)#
#
## vector of timesteps#
times  <- seq(0, 100, length = 101)#
#
## external signal with rectangle impulse#
signal <- as.data.frame(list(times = times,#
                            import = rep(0,length(times))))#
#
signal$import[signal$times >= 10 & signal$times <= 11] <- 0.2#
#
sigimp <- approxfun(signal$times, signal$import, rule = 2)#
## Start values for steady state#
y <- xstart <- c(S = 1, P = 1, C = 1)#
#
## Solving#
out <-  lsoda(xstart, times, SPCmod, parms) #
########################################################
########################################################
# 2. Calculation of tree likelihood under a BirthDeath process#
########################################################
########################################################
library(ape)#
#trfn = "tree_small.newick"#
trstr = "((chimp:1,human:1):1,gorilla:2);"#
tr = read.tree(file="", text=trstr)#
plot(tr)#
axisPhylo()#
#
# Get the ML estimates of birthRate (speciation rate) #
# and deathRate (extinction rate)#
# ...using ape::birthdeath#
BD =  birthdeath(tr)#
BD#
names(BD)#
#
# Calculate the birthRate and deathRate from the outputs#
x1 = unname(BD$para["d/b"])#
x2 = unname(BD$para["b-d"])#
deathRate = (x2*x1) / (1-x1)#
birthRate = deathRate+x2#
c(birthRate, deathRate)#
#
# You should get:#
# c(birthRate, deathRate)#
# [1] 0.2222222 0.0000000#
#
# Get the log-likelihood of the tree under the ML parameters#
# Convert the deviance to likelihood#
BD_LnL = -1 * BD$dev / 2#
BD_LnL#
# -3.216395#
# Set birthRate#
#birthRate = 0.22222222222222222222#
########################################################
# Likelihood equation in the birthdeath function#
########################################################
N <- length(tr$tip.label)#
nb_node = tr$Nnode - 1#
sptimes <- c(NA, branching.times(tr)) # NA so the number of times equals number of tips?#
# a = "d/b"#
# r = "b-d"#
#
dev <- function(a=0.1, r=0.2, N, x, return_deviance=FALSE)#
	{#
	if (r < 0 || a > 1) #
		return(1e+100)#
	lnl_topology = lfactorial(tr$Nnode)#
	lnl_numBirths = nb_node * log(r)#
	lnl_Births_above_root = r * sum(sptimes[3:N])#
	lnl_numtips_wOneMinusDeathRate = N * log(1 - a)#
	# Interpretation: more tips are less likely, if relativeDeathRate is >0#
	# If relativeDeathRate = 1, a=0, and lnl=-Inf... #
	#    CLEARLY WRONG EXCEPT IN A MAXIMUM LIKELIHOOD CONTEXT!!!#
	# If relativeDeathRate = 0, a=0, and lnl=0, i.e. any number of tips is equiprobable#
	lnl_branching_times = -2 * sum(log(exp(r * sptimes[2:N]) - a))#
	# For each observed branching,#
	# netDiversificationRate * timeOfEvent <- take exponent of that ; this means recorded events are less likely in the past#
	# <- subtract "a", a constant (relativeDeathRate)#
	##
	# This would be a straight likelihood as:#
	# 1/#
	# (exp(r*branching_time)-a)^2#
	##
	# Sum the logs of these#
	##
	# If deathRate = 0#
	# lnl_branching_times = -2 * sum(log(exp(birthRate*sptimes[2:N]) - 0))#
	# lnl_branching_times = -2 * sum(log( exp(birthRate*sptimes[2:N]) )#
	# lnl_branching_times = -2 * sum( birthRate*sptimes[2:N] )#
	##
	# Note: sum(X) = 9 = total branchlength of tr#
	# In BD:#
	# -2*sum(sptimes[2:N]) = -12#
	# sum(sptimes[3:N]) = 3#
	# So, lnl_branching_times + lnl_Births_above_root = yule's -lambda * X#
	if (return_deviance == TRUE)#
		{#
		result = -2 * (lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times)#
		} else {#
		result = lnl_topology + lnl_numBirths + lnl_Births_above_root + #
			lnl_numtips_wOneMinusDeathRate + lnl_branching_times#
		}#
	return(result)#
	}#
dev(a=0.1, r=0.2, N=N, x=x)#
# -4.063987#
#
dev(a=x1, r=x2, N=N, x=x)#
# -3.216395#
#
dev(a=deathRate/birthRate, r=birthRate-deathRate, N=N, x=x)#
# -3.216395#
#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
#
birthRate = 0.222222222222#
dev(a=0/birthRate, r=birthRate-0, N=N, x=x)#
S <- rep(1, times=length(tr$tip.label))#
bd.ext(phy=tr, S=S, conditional=TRUE)#
#       d / b = 2.883955e-07   StdErr = NaN #
#       b - d = 0.2656457   StdErr = NaN #
#
bd.ext(phy=tr, S=S, conditional=FALSE) # same than older versions#
#      d / b = 4.949791e-06   StdErr = NaN #
#      b - d = 0.242636   StdErr = NaN #
########################################################
########################################################
# 3. Calculation of tree likelihood under a Yule process#
########################################################
########################################################
yule(phy=tr)#
# $lambda#
# [1] 0.2222222#
# #
# $se#
# [1] 0.1571348#
# #
# $loglik#
# [1] -3.216395#
# #
# attr(,"class")#
# [1] "yule"#
########################################################
# Yule likelihood#
########################################################
yule_lik <- function(tr)#
	{#
	# Total length of tree#
	X <- sum(tr$edge.length)#
#
	# Number of internal nodes#
	tr$Nnode#
	# Number of internal nodes, minus root#
	nb_node <- tr$Nnode - 1#
  # ML estimate of lambda (birthrate)#
  lambda <- nb_node/X#
  # Standard error of ML estimate#
  se <- lambda/sqrt(nb_node)#
  # Log-likelihood#
  lnl_topology = lfactorial(tr$Nnode)#
  lnl_numBirths = nb_node * log(lambda)#
  loglik = -lambda * X + lnl_topology + lnl_numBirths#
  loglik#
  # -3.216395#
  res = NULL#
  res$lambda = lambda#
  res$se = se#
  res$loglik = loglik#
  return(res)#
  }#
#
yule_lik(tr=tr)#
# -3.216395 #
########################################################
########################################################
# 3. Set up of equivalent BiSSE model for DEC, starting values#
########################################################
########################################################
#
# ClaSSE helper functions#
library(diversitree)#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")#
###################################################
# Set up states for BiSSE to match DEC states#
###################################################
#
# States in the BiSSE model, and how they correspond#
# to the geographic ranges in DEC#
# #
# ====================#
# (statenum = range)#
# ====================#
# 1 = null range#
# 2 = A = Africa#
# 3 = B = Asia#
# 4 = AB = both#
# ====================#
#
# States at the tips of the tree#
# (ranges A, A, A, B)#
#states = c(1, 1, 1, 1)#
states = c(0, 1, 1) # 3 states for 3 tips#
names(states) = tr$tip.label#
states#
# Proportion of species in each state; for 2 states#
# (Let's assume we have all species)#
sampling.f = c(1,1)  # length(sampling.f) = 2 states#
#
# Number of states#
k = 2#
#
# Make the BiSSE likelihood function. #
# (strict=FALSE means that some states in the state space can be absent from the tips)#
bisse_2areas = diversitree::make.bisse(tree=tr, states=states, sampling.f=sampling.f, strict=FALSE)#
#
# Look at all the parameters of this model!#
# lambdas = speciation rates#
# mus = extinction rates#
# qs = anagenetic transition rates#
birthRate = 0.222222222#
deathRate = 1.2#
#
lambda0 = birthRate*2#
lambda1 = birthRate#
mu0 = deathRate#
mu1 = deathRate*2#
q01 = 0.4#
q10 = 0.2#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
bisse_params = parms#
#
# Constraint parameters so you are only fitting 1 birthRate#
# constraints = list(lambda0~lambda1, mu0~mu1, q01~q10)#
# bisse_2areas_constrained = constrain(f=bisse_2areas, formulae=constraints)#
# #
# Wait 1 seconds#
# fit <- find.mle(func=bisse_2areas_constrained, x.init=bisse_params, method="subplex")#
# fit$par.full#
# fit$lnLik#
# #
# Compare to Yule#
# yule(tr)#
# #
# bisse_params_orig = bisse_params#
# bisse_params = fit$par.full#
#
res1 = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0, 1)#
res3 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.25, 0.75)#
res4 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = c(0.5,0.5)#
res5 = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
# Res1t is BiSSE default#
res1t = bisse_2areas(pars=bisse_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = bisse_2areas(pars=bisse_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0, 1)#
res3t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.25, 0.75)#
res4t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = c(0.5,0.5)#
res5t = bisse_2areas(pars=bisse_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = bisse_2areas(pars=bisse_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base#
# Columns 3-4 sum to 1#
rowSums(base[,3:4])#
#
lq = attr(res2, "intermediates")$lq#
lq#
sum(lq)#
########################################################
########################################################
# 5. BiSSE likelihoods and comparison to yule#
########################################################
########################################################
birthRate#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
#
bisse_params = parms#
#
# Starting values of state variables#
E0t = 0#
E1t = 0#
D0t = 0#
D1t = 1#
y = c(E0t, E1t, D0t, D1t)#
names(y) = c("E0t", "E1t", "D0t", "D1t")#
y#
#
# t = current time point of integration#
# y = state variable we are tracking (named)  MUST HAVE NAMES!!!#
# parms = model parameters (named)            MUST HAVE NAMES!!!#
#
define_BiSSE_eqns_in_R <- function(t, y, parms)#
	{#
	with(data=#
	as.list(c(y, parms)), #
		{ # expr#
		# When the limit is taken as deltaT goes to 0, the#
		# change in E0 in dt is:#
		# probs of: #
		# - extinction#
		# - no change but later extinction#
		# - state change, then extinction#
		# - no change, speciation, extinction of both#
		dE0t <- mu0 - (mu0 + q01 + lambda0)*E0t + q01*E1t + lambda0*(E0t)^2#
		dE1t <- mu1 - (mu1 + q10 + lambda1)*E1t + q10*E0t + lambda1*(E1t)^2#
#
		# probs of:#
		# - no change#
		# - character change, no speciation#
		# - speciation followed by extinction of 1#
		# - extinction (prob of observed clade = 0, since the clade is extant)#
		dD0t <- -1*(lambda0 + mu0 + q01)*D0t + q01*D1t + 2*lambda0*E0t*D0t + 0#
		dD1t <- -1*(lambda1 + mu1 + q10)*D1t + q10*D0t + 2*lambda1*E1t*D1t + 0#
#
		# Return the list of coupled differential equations#
		res <- c(dE0t, dE1t, dD0t, dD1t)#
		return(list(res))#
		#return(list_of_diff_eqns)#
		}#
	)#
	}#
#
# One step test:#
one_step_result = define_BiSSE_eqns_in_R(t=t, y=y, parms=parms)#
one_step_result#
# [[1]]#
# [1]  0.0000000  0.0000000  0.0000000 -0.2222222#
#
# LSODA inputs:#
# y = initial state values#
# times = times at which you want estimates#
# func#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
out#
#
parms2 = parms#
parms2["mu0"] = 0.1#
parms2["mu1"] = 0.1#
times = seq(0,1,1/50)#
out <- lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms2) #
out#
# Downpass#
numsteps = 100000#
numstates = 2#
num_internal_nodes = tr$Nnode#
numtips = length(tr$tip.label)#
num_internal_nodes = tr$Nnode#
numnodes = numtips + num_internal_nodes#
tipnums <- 1:numtips#
# Reorder the edge matrix into pruningwise order#
# This is CRUCIAL!!#
tr2 <- reorder(tr, "pruningwise")#
edgelengths = tr2$edge.length#
# Define matrices to store data#
# We have Es for each state, and Ds for each state#
# But we only need to record the Ds#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Fill in the likelihoods of tip nodes manually#
#tip_states_Ds = y[c(((length(y)/2)+1), length(y))]#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[1,numstates] = 1	# chimp#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[2,1] = 1	# human#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE[3,numstates] = 1	# gorilla#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang if a different state#
# condlikes_of_each_treeState_BRANCHTOP_AT_NODE[4,numstates] = 1	# orang same states for all tips#
#
zeros = matrix(data=0, nrow=numnodes, ncol=numstates)#
condlikes_of_each_treeState_BRANCHTOP_AT_NODE = cbind(zeros, condlikes_of_each_treeState_BRANCHTOP_AT_NODE)#
condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
#
relative_probs_of_each_state_BRANCHTOP_AT_NODE = condlikes_of_each_treeState_BRANCHTOP_AT_NODE[,3:4]#
relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] = relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,] / rowSums(relative_probs_of_each_state_BRANCHTOP_AT_NODE[1:numtips,])#
#
relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates)#
#
# Store both the Es and the Ds likelihoods#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS = condlikes_of_each_treeState_BRANCHTOP_AT_NODE#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS = matrix(data=0, nrow=numnodes, ncol=numstates*2)#
#
computed_likelihoods_at_each_node = rep(0, numnodes)#
computed_likelihoods_at_each_node[1:numtips] = 1#
computed_likelihoods_at_each_node_x_lambda = computed_likelihoods_at_each_node#
# DEFINE DOWNPASS THROUGH THE BRANCHES	#
i = 1#
edges_to_visit = seq(from=1, by=2, length.out=num_internal_nodes)#
#
# Speciation#
lambda0 = bisse_params["lambda0"]#
lambda1 = bisse_params["lambda1"]#
# Extinction#
mu0 = bisse_params["mu0"]#
mu1 = bisse_params["mu1"]#
# Character transition#
q01 = bisse_params["q01"]#
q10 = bisse_params["q10"]#
#
parms = c(lambda0, lambda1, mu0, mu1, q01, q10)#
names(parms) = c("lambda0", "lambda1", "mu0", "mu1", "q01", "q10")#
parms#
numsteps=100#
#
names_y = c("E0t", "E1t", "D0t", "D1t")#
#
i = 1#
for (i in edges_to_visit)#
	{#
	# First edge visited is i#
	#print(i)#
	# Its sister is j #
	j <- i + 1#
#
	# Get the node numbers at the tips of these two edges		#
	left_desc_nodenum <- tr2$edge[i, 2]#
	right_desc_nodenum <- tr2$edge[j, 2]#
	left_edgenum_TF = tr2$edge[, 2] == left_desc_nodenum#
	right_edgenum_TF = tr2$edge[, 2] == right_desc_nodenum#
	left_edgenum = (1:length(edgelengths))[left_edgenum_TF]#
	right_edgenum = (1:length(edgelengths))[right_edgenum_TF]#
	# And for the ancestor edge (i or j shouldn't matter, should produce the same result!!!)#
	anc <- tr2$edge[i, 1]#
	# Calculate the downpass on two branches#
	# The Es are 0 (no extinctions above, already accounted for)#
	# Left branch#
	# The Ds are relative state probabilities#
	edgelength_Left = edgelengths[left_edgenum]#
	times = seq(from=0, to=edgelength_Left, by=edgelength_Left/numsteps)#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[left_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixL = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempLeft = out_matrixL[nrow(out_matrixL),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = condlikes_tempLeft#
	condExtinct_Left = condlikes_tempLeft[1:2]#
	condlikes_Left = condlikes_tempLeft[3:4]#
#
	# #
	# R, 100 steps, mu=0#
	# 100 1.00   0   0 0.7687171 0.0338017454#
	# HiSSE, 2 steps, tiny mu#
	# 2    1 1.992624e-07 1.992624e-07 0.7666849 0.03405248#
	# HiSSE, 100 steps#
	# 100 1.00 1.974810e-07 1.974810e-07 0.7687171 0.0338017546#
	# Right branch#
	edgelength_Right = edgelengths[right_edgenum]#
	times = seq(from=0, to=edgelength_Right, by=edgelength_Right/numsteps)#
	# The Ds are relative state probabilities#
	y = condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[right_desc_nodenum,]#
	names(y) = names_y#
#
	out_matrixR = lsoda(y=y, times=times, func=define_BiSSE_eqns_in_R, parms=parms) #
	condlikes_tempRight = out_matrixR[nrow(out_matrixR),][2:5]#
	condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = condlikes_tempRight#
	condExtinct_Right = condlikes_tempRight[1:2]#
	condlikes_Right = condlikes_tempRight[3:4]#
	# Conditional likelihoods of states at the bottom of right branch#
	#condlikes_Right = independent_likelihoods_on_each_branch[[j]] %*% relative_probs_of_each_state_BRANCHTOP_AT_NODE[right_desc_nodenum,]#
	# Every node (except maybe the root) has a branch below it, and there is also a #
	# relative_probs_of_each_state_BRANCHTOP_AT_NODE at the bottom of this branch#
	condprobs_Left = condlikes_Left / sum(condlikes_Left)#
	condprobs_Right = condlikes_Right / sum(condlikes_Right)#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] = condprobs_Left#
	relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,] = condprobs_Right#
	# If there is no speciational model, you are assuming 100% sympatry (range duplication)#
	# at each speciation event#
	##
	# In this case, you can just multiply the two conditional likelihood matrices together#
	##
	# Also, if a branch is extremely short (a "hook"), this is essentially a zero-length#
	# branch, we are assuming that this represents the range of a lineage at that #
	# point.  There is no speciation event here -- both "lineages" inherit#
	# the same range.  This allows fossils to closely influence ancestral states.#
	##
	# This was developed with Kaitlin Maguire over several years of screwing around.#
#
	# Check for a short "hook" branch; if found, use just allopatric speciational model#
#
	# get the correct edge#
	left_edge_TF = tr2$edge[,2] == left_desc_nodenum#
	right_edge_TF = tr2$edge[,2] == right_desc_nodenum#
	node_likelihood = condlikes_Left * condlikes_Right#
	lambda0 = parms["lambda0"]#
	lambda1 = parms["lambda1"]#
	node_likelihood_x_lambda = node_likelihood * c(lambda0, lambda1)#
	E_average = colMeans(rbind(condExtinct_Left, condExtinct_Right))#
	# birthRate*base[1,3:4]^2#
	D_relprobs_multiplied = relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[left_desc_nodenum,] * relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS[right_desc_nodenum,]#
	D_combined = c(lambda0, lambda1) * D_relprobs_multiplied#
#
	# Store the various options#
	condlikes_of_each_treeState_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood)#
	condlikes_of_each_treeState_x_lambda_BRANCHTOP_AT_NODE[anc,] = c(E_average, node_likelihood_x_lambda)#
	condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS[anc, ] = c(E_average, D_combined)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[left_desc_nodenum,] = c(E_average, condprobs_Left)#
	condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[right_desc_nodenum,] = c(E_average, condprobs_Right)#
	# node_likelihood_x_lambda#
	#          D0t          D1t #
    # 0.1313168545 0.0002539018 #
# 	> v*c(0.333333, 0.333333)#
# 			  D0           D1 #
# 	0.1306233807 0.0002576823 #
# 	> v#
# 			 D0          D1 #
# 	0.587805801 0.001159572 #
# 	>  sequence(length(desRows))#
# 	[1] 1 2#
# 	> compD[focal,]#
# 	[1] 0.1306233895 0.0002576823#
	total_likelihood_for_node = sum(node_likelihood)#
	total_likelihood_for_node_x_lambda = sum(node_likelihood_x_lambda)#
	computed_likelihoods_at_each_node[anc] = total_likelihood_for_node#
	computed_likelihoods_at_each_node_x_lambda[anc] = sum(total_likelihood_for_node_x_lambda)#
	#print(total_likelihood_for_node)#
	relative_probs_of_each_state_BRANCHTOP_AT_NODE[anc, ] = node_likelihood_x_lambda / total_likelihood_for_node_x_lambda#
	} # END for (i in edges_to_visit)#
########################################################
########################################################
# START PROOF OF MATCHING THIS CODE TO DIVERSITREE#
########################################################
########################################################
# Best, matches diversitree BiSSE "init"#
init#
#           [,1]      [,2]      [,3]        [,4]#
# [1,] 0.0000000 0.0000000 1.0000000 0.000000000#
# [2,] 0.0000000 0.0000000 0.0000000 1.000000000#
# [3,] 0.0000000 0.0000000 0.0000000 1.000000000#
# [4,] 0.8988459 0.9775416 0.2597286 0.009541766#
# [5,] 0.6888798 0.8799765 0.1518462 0.015528271#
condlikes_treeStates_BRANCHTOP_AT_NODE_DOWNPASS#
#           [,1]      [,2]       [,3]       [,4]#
# [1,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [2,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [3,] 0.0000000 0.0000000 0.00000000 1.00000000#
# [4,] 0.8988459 0.9775416 0.20907825 0.02186927#
# [5,] 0.6888798 0.8799766 0.06604511 0.08391649#
# Matches matches diversitree BiSSE "base" -- but a weird combination of #
# - left columns: average E's passed down#
# - right columns: normalized conditional likelihoods#
base#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]      [,3]      [,4]#
# [1,] 0.6888798 0.8799765 0.8862882 0.1137118#
# [2,] 0.6888798 0.8799765 0.3854885 0.6145115#
# [3,] 0.8988459 0.9775416 0.6725996 0.3274004#
# [4,]        NA        NA        NA        NA#
# [5,] 0.8988459 0.9775416 0.8688519 0.1311481#
condlikesProbs_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]      [,3]      [,4]#
# [1,] 0.6888798 0.8799766 0.3854886 0.6145114#
# [2,] 0.6888798 0.8799766 0.3854886 0.6145114#
# [3,] 0.8988459 0.9775416 0.6725994 0.3274006#
# [4,] 0.0000000 0.0000000 0.0000000 0.0000000#
# [5,] 0.8988459 0.9775416 0.6994149 0.3005851#
# lq and likelihoods#
condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS#
#           [,1]      [,2]       [,3]        [,4]#
# [1,] 0.6888798 0.8799766 0.05141641 0.081963417#
# [2,] 0.6888798 0.8799766 0.05141641 0.081963417#
# [3,] 0.8988459 0.9775416 0.01959357 0.009537547#
# [4,] 0.0000000 0.0000000 0.00000000 0.000000000#
# [5,] 0.8988459 0.9775416 0.02373981 0.010202572#
#
# Matches diversitree BiSSE "lq"#
lnls = log(rowSums(condlikes_treeStates_BRANCHBOTTOM_BELOW_NODE_DOWNPASS[,3:4]))#
lnls[!is.finite(lnls)] = NA#
lnls#
sum(lnls, na.rm=TRUE)#
# -1.526391 -2.014554 -3.535949  0.000000 -3.012482#
sum(lnls, na.rm=TRUE)#
# -10.08938#
# Sum of the branch likelihoods#
lq#
sum(lq)#
# -1.526391 -2.014554 -3.535949  0.000000 -3.012482#
# -10.08938#
#
# Add the root probabilities#
# Assuming diversitree options:#
# root=ROOT.OBS, root.p=NULL, condition.surv=FALSE#
# i.e., the root state probs are just the root_Ds/sum(root_Ds)#
LnLs1#
# -11.47222 -10.08938#
#
# root=ROOT.OBS, root.p=NULL, condition.surv=TRUE#
LnLs1t#
# -6.043899 -10.089376#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = sum(log(computed_likelihoods_at_each_node_x_lambda))#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda#
# -14.31109#
R_result_branch_lnL = -10.08938#
R_result_total_LnLs1 = -11.47222#
R_result_total_LnLs1t = -6.043899#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -14.31109#
########################################################
########################################################
# END PROOF OF MATCHING
# Load the package (after installation, see above).#
library(GenSA)    # GenSA is better than optimx (although somewhat slower)#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
#
########################################################
# 2018-10-10 update: I have been putting the #
# updates on CRAN/GitHub#
# You should use:#
# rexpokit version 0.26.6 from CRAN#
# cladoRcpp version 0.15 from CRAN#
# BioGeoBEARS version 1.1 from GitHub, install with:#
# library(devtools)#
# devtools::install_github(repo="nmatzke/BioGeoBEARS")#
########################################################
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
########################################################
# CUT: The old instructions to source() online upgrade .R files have been deleted,#
#         all updates are now on the GitHub version of the package, version 1.1+#
########################################################
#
########################################################
# (This local-sourcing is mostly useful for Nick, while actively developing)#
# Local source()-ing method -- uses BioGeoBEARS sourceall() function #
# on a directory of .R files, so you don't have to type them out.#
# The directories here are on my machine, you would have to make a #
# directory, save the .R files there, and refer to them.#
##
# NOTE: it's best to source the "cladoRcpp.R" update first, to avoid warnings like this:#
###
## Note: possible error in 'rcpp_calc_anclikes_sp_COOweights_faster(Rcpp_leftprobs = tmpca_1, ': #
##         unused arguments (m = m, m_null_range = include_null_range, jts_matrix = jts_matrix) #
###
##
# TO USE: Delete or comment out the 'source("http://...")' commands above, and un-comment#
#              the below...#
#########################################################################
# Un-comment (and fix directory paths) to use:#
#library(BioGeoBEARS)#
#source("/drives/Dropbox/_njm/__packages/cladoRcpp_setup/cladoRcpp.R")#
#sourceall("/drives/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#calc_loglike_sp = compiler::cmpfun(calc_loglike_sp_prebyte)    # crucial to fix bug in uppass calculations#
#calc_independent_likelihoods_on_each_branch = compiler::cmpfun(calc_independent_likelihoods_on_each_branch_prebyte)#
#########################################################################
#
########################################################
# SETUP: YOUR WORKING DIRECTORY#
########################################################
# You will need to set your working directory to match your local system#
#
# Note these very handy functions!#
# Command "setwd(x)" sets your working directory#
# Command "getwd()" gets your working directory and tells you what it is.#
# Command "list.files()" lists the files in your working directory#
# To get help on any command, use "?".  E.g., "?list.files"#
#
# Set your working directory for output files#
# default here is your home directory ("~")#
# Change this as you like#
wd = np("~")#
setwd(wd)#
#
# Double-check your working directory with getwd()#
getwd()#
#
########################################################
# SETUP: Extension data directory#
########################################################
# When R packages contain extra files, they are stored in the "extdata" directory #
# inside the installed package.#
##
# BioGeoBEARS contains various example files and scripts in its extdata directory.#
# #
# Each computer operating system might install BioGeoBEARS in a different place, #
# depending on your OS and settings. #
# #
# However, you can find the extdata directory like this:#
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny (plots to a PDF, which avoids issues with multiple graphics in same window):#
pdffn = "tree.pdf"#
pdf(file=pdffn, width=9, height=12)#
#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)#
#
########################################################
# Geography file#
# Notes:#
# 1. This is a PHYLIP-formatted file. This means that in the #
#    first line, #
#    - the 1st number equals the number of rows (species)#
#    - the 2nd number equals the number of columns (number of areas)#
#    - after a tab, put the areas in parentheses, with spaces: (A B C D)#
##
# 1.5. Example first line:#
#    10    4    (A B C D)#
# #
# 2. The second line, and subsequent lines:#
#    speciesA    0110#
#    speciesB    0111#
#    speciesC    0001#
#         ...#
# #
# 2.5a. This means a TAB between the species name and the area 0/1s#
# 2.5b. This also means NO SPACE AND NO TAB between the area 0/1s.#
# #
# 3. See example files at:#
#    http://phylo.wikidot.com/biogeobears#files#
# #
# 4. Make you understand what a PLAIN-TEXT EDITOR is:#
#    http://phylo.wikidot.com/biogeobears#texteditors#
##
# 3. The PHYLIP format is the same format used for C++ LAGRANGE geography files.#
##
# 4. All names in the geography file must match names in the phylogeny file.#
##
# 5. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
##
# 6. Operational taxonomic units (OTUs) should ideally be phylogenetic lineages, #
#    i.e. genetically isolated populations.  These may or may not be identical #
#    with species.  You would NOT want to just use specimens, as each specimen #
#    automatically can only live in 1 area, which will typically favor DEC+J #
#    models.  This is fine if the species/lineages really do live in single areas,#
#    but you wouldn't want to assume this without thinking about it at least. #
#    In summary, you should collapse multiple specimens into species/lineages if #
#    data indicates they are the same genetic population.#
#######################################################
#
# This is the example geography file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))#
#
# Look at the raw geography text file:#
moref(geogfn)#
#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Set the maximum number of areas any species may occupy; this cannot be larger #
# than the number of areas you set up, but it can be smaller.#
max_range_size = 4#
#
#####################################################
#####################################################
# KEY HINT: The number of states (= number of different possible geographic ranges)#
# depends on (a) the number of areas and (b) max_range_size.#
# If you have more than about 500-600 states, the calculations will get REALLY slow,#
# since the program has to exponentiate a matrix of e.g. 600x600.  Often the computer#
# will just sit there and crunch, and never get through the calculation of the first#
# likelihood.#
# #
# (this is also what is usually happening when LAGRANGE hangs: you have too many states!)#
##
# To check the number of states for a given number of ranges, try:#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=FALSE)#
numstates_from_numareas(numareas=4, maxareas=3, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=2, include_null_range=TRUE)#
#
# Large numbers of areas have problems:#
numstates_from_numareas(numareas=10, maxareas=10, include_null_range=TRUE)#
#
# ...unless you limit the max_range_size:#
numstates_from_numareas(numareas=10, maxareas=2, include_null_range=TRUE)#
#####################################################
#####################################################
#
########################################################
########################################################
# DEC AND DEC+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DEC" model is identical with #
# the Lagrange DEC model, and should return identical#
# ML estimates of parameters, and the same #
# log-likelihoods, for the same datasets.#
##
# Ancestral state probabilities at nodes will be slightly #
# different, since BioGeoBEARS is reporting the #
# ancestral state probabilities under the global ML#
# model, and Lagrange is reporting ancestral state#
# probabilities after re-optimizing the likelihood#
# after fixing the state at each node. These will #
# be similar, but not identical. See Matzke (2014),#
# Systematic Biology, for discussion.#
##
# Also see Matzke (2014) for presentation of the #
# DEC+J model.#
########################################################
########################################################
#
########################################################
########################################################
#
########################################################
# Run DEC#
########################################################
#
# Intitialize a default model (DEC model)#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
# Give BioGeoBEARS the location of the phylogeny Newick file#
BioGeoBEARS_run_object$trfn = trfn#
#
# Give BioGeoBEARS the location of the geography text file#
BioGeoBEARS_run_object$geogfn = geogfn#
#
# Input the maximum range size#
BioGeoBEARS_run_object$max_range_size = max_range_size#
#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; OMeara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
# 1. Here, un-comment ONLY the files you want to use.#
# 2. Also un-comment "BioGeoBEARS_run_object = section_the_tree(...", below.#
# 3. For example files see (a) extdata_dir, #
#  or (b) http://phylo.wikidot.com/biogeobears#files#
#  and BioGeoBEARS Google Group posts for further hints)#
##
# Uncomment files you wish to use in time-stratified analyses:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
# (use more cores to speed it up; this requires#
# library(parallel) and/or library(snow). The package "parallel" #
# is now default on Macs in R 3.0+, but apparently still #
# has to be typed on some Windows machines. Note: apparently #
# parallel works on Mac command-line R, but not R.app.#
# BioGeoBEARS checks for this and resets to 1#
# core with R.app)#
#
# Sparse matrix exponentiation is an option for huge numbers of ranges/states (600+)#
# I have experimented with sparse matrix exponentiation in EXPOKIT/rexpokit,#
# but the results are imprecise and so I haven't explored it further.#
# In a Bayesian analysis, it might work OK, but the ML point estimates are#
# not identical.#
# Also, I have not implemented all functions to work with force_sparse=TRUE.#
# Volunteers are welcome to work on it!!#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC model#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
# Run this to check inputs. Read the error messages if you get them!#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = TRUE#
resfn = "Psychotria_DEC_M0_unconstrained_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDEC = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDEC = res#
    }#
#
########################################################
# Run DEC+J#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; OMeara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
#BioGeoBEARS_run_object$timesfn = "timeperiods.txt"#
#BioGeoBEARS_run_object$dispersal_multipliers_fn = "manual_dispersal_multipliers.txt"#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC+J model#
# Get the ML parameter values from the 2-parameter nested model#
# (this will ensure that the 3-parameter model always does at least as good)#
dstart = resDEC$outputs@params_table["d","est"]#
estart = resDEC$outputs@params_table["e","est"]#
jstart = 0.0001#
#
# Input starting values for d, e#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = estart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = estart#
#
# Add j as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
resfn = "Psychotria_DEC+J_M0_unconstrained_v1.Rdata"#
runslow = TRUE#
if (runslow)#
    {#
    #sourceall("/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
#
    resDECj = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDECj = res#
    }#
#
########################################################
# PDF plots#
########################################################
pdffn = "Psychotria_DEC_vs_DEC+J_M0_unconstrained_v1.pdf"#
pdf(pdffn, width=6, height=6)#
#
########################################################
# Plot ancestral states - DEC#
########################################################
analysis_titletxt ="BioGeoBEARS DEC on Psychotria M0_unconstrained"#
#
# Setup#
results_object = resDEC#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res2 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
########################################################
# Plot ancestral states - DECJ#
########################################################
analysis_titletxt ="BioGeoBEARS DEC+J on Psychotria M0_unconstrained"#
#
# Setup#
results_object = resDECj#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
dev.off()  # Turn off PDF#
cmdstr = paste("open ", pdffn, sep="")#
system(cmdstr) # Plot it
?tiplabels
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges, show.tip.label=FALSE)#
for(i in seq_along(tr$tip.label)){#
    tip <- unlist(strsplit(tr$tip.label[i], "_"))#
#
    tiplabels(#
        bquote(italic(.(paste(tip[-length(tip)], collapse = ' '))) ~ .(tip[length(tip)])),#
        tip = i, adj = c(0, 0.5), frame = "n", bg = "white"#
    )#
#
}
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges, show.tip.label=FALSE)
for(i in seq_along(tr$tip.label)){#
    tip <- unlist(strsplit(tr$tip.label[i], "_"))#
#
    tiplabels(#
        bquote(italic(.(paste(tip[-length(tip)], collapse = ' '))) ~ .(tip[length(tip)])),#
        tip = i, adj = c(0, 0.5), frame = "n", bg = "white"#
    )#
#
}
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges, show.tip.label=TRUE, tipcol="white")#
#
# From: #
# https://stackoverflow.com/questions/43378199/italics-and-regular-text-in-phylogeny-tip-labels-in-r#
for(i in seq_along(tr$tip.label)){#
    tip <- unlist(strsplit(tr$tip.label[i], "_"))#
#
    tiplabels(#
        bquote(italic(.(paste(tip[-length(tip)], collapse = ' '))) ~ .(tip[length(tip)])),#
        tip = i, adj = c(0, 0.5), frame = "n", bg = "white"#
    )#
#
}
plot_BioGeoBEARS_results
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges, show.tip.label=TRUE, tipcol="white", xlims=c(0,8))#
#
# From: #
# https://stackoverflow.com/questions/43378199/italics-and-regular-text-in-phylogeny-tip-labels-in-r#
for(i in seq_along(tr$tip.label)){#
    tip <- unlist(strsplit(tr$tip.label[i], "_"))#
#
    tiplabels(#
        bquote(italic(.(paste(tip[-length(tip)], collapse = ' '))) ~ .(tip[length(tip)])),#
        tip = i, adj = c(0, 0.5), frame = "n", bg = "white"#
    )#
#
}
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges, show.tip.label=TRUE, tipcol="white", xlims=c(0,8))#
#
# From: #
# https://stackoverflow.com/questions/43378199/italics-and-regular-text-in-phylogeny-tip-labels-in-r#
for(i in seq_along(tr$tip.label)){#
    tip <- unlist(strsplit(tr$tip.label[i], "_"))#
#
    tiplabels(#
        bquote(italic(.(paste(tip[-length(tip)], collapse = ' '))) ~ .(tip[length(tip)])),#
        tip = i, adj = c(0, 0.5), frame = "n", bg = "white", label.offset=0.45#
    )#
#
}
warnings()
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges, show.tip.label=TRUE, tipcol="white", xlims=c(0,8))#
#
# From: #
# https://stackoverflow.com/questions/43378199/italics-and-regular-text-in-phylogeny-tip-labels-in-r#
for(i in seq_along(tr$tip.label)){#
    tip <- unlist(strsplit(tr$tip.label[i], "_"))#
#
    tiplabels(#
        bquote(italic(.(paste(tip[-length(tip)], collapse = ' '))) ~ .(tip[length(tip)])),#
        tip = i, adj = c(0, 0.5), frame = "n", bg = "white", offset=0.45#
    )#
#
}
########################################################
# Compare BioGeoBEARS and diversitree-ClaSSE calculations#
##
# This script will illustrate, for any input tree#
# and geography file, and BioGeoBEARS parameters, the #
# equivalence of comparing BioGeoBEARS models (such as #
# DEC and DEC+J, but this applies to any 2 models) and #
# comparing 2 equivalent ClaSSE models, in the case where:#
##
# * the claSSE lambdas = BGB_cladogenesis_probs * birthRate#
# * the birthRate = the Maximum Likelihood estimate under Yule#
# * the sampling is assumed to be 100%#
##
# The key insight is that BioGeoBEARS calculates the #
# likelihood of the geography data (just a complex #
# character dataset). Adding a Yule process likelihood, #
# i.e. the probability density of a tree under a pure-birth#
# process with an extinction rate of 0 and assuming #
# complete sampling, creates a special case of the #
# ClaSSE model.#
##
# Therefore, comparing the likelihood difference between#
# two BioGeoBEARS models is exactly equivalent to comparing#
# two equivalent ClaSSE models. The likelihood difference#
# will be identical, because the Yule-process likelihood#
# is a constant across the different BioGeoBEARS of the #
# geography data.#
##
# Note: This is only set up for non-time-stratified analyses.#
# Also, the Yule-process assumption fails for a tree#
# that includes fossils (non-contemporaneous tips).#
# #
########################################################
#
library(ape)#
library(diversitree)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_functions_v3.R")  # utility functions from diversitree#
source("/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R")       # helper functions in plain-R#
wd = "/GitHub/BioGeoJulia.jl/Rsrc/"#
setwd(wd)#
#
# Load simple example tree (newick format, must be ultrametric, i.e. #
# all the tips come to the present)#
trfn = "Psychotria_tree.newick"#
tr = read.tree(trfn)#
#
# Load geography data#
geogfn = "Psychotria_geog.data"#
########################################################
# BioGeoBEARS Q and C matrices#
########################################################
library(BioGeoBEARS)#
max_range_size = 4#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
include_null_range = BioGeoBEARS_run_object$include_null_range#
#
# Add j as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = 0.001#
# Run the Maximum Likelihood optimization#
res = bears_optim_run(BioGeoBEARS_run_object)#
res$total_loglikelihood
mats = get_Qmat_COOmat_from_res(res, numstates=ncol(res$ML_marginal_prob_each_state_at_branch_top_AT_node), include_null_range=res$inputs$include_null_range, max_range_size=res$inputs$max_range_size, timeperiod_i=1)#
numstates = length(mats$states_list)
birthRate = 0.3288164        # 0.3288164 for Psychotria tree#
birthRate = yule(tr)$lambda  # The ML lambda from Yule. Equals (#speciations-1)/tree_length#
birthRate#
(tr$Nnode-1)/sum(tr$edge.length)#
#
deathRate = 0.0     # Yule process means 0.0 extinction rate#
d_val = 0.03505038	# ML estimate for Psychotria under DEC model#
e_val = 0.02832370	# ML estimate for Psychotria under DEC model#
j_val = 0.0         # Under DEC, j=0.0#
d_val = res$output@params_table["d","est"] # Extract from ML result#
e_val = res$output@params_table["e","est"] # Extract from ML result#
j_val = 0.0
d_val
e_val
j_val
res$output@params_table["J","est"]
j_val = res$output@params_table["j","est"]
j_val
d_val = res$output@params_table["d","est"] # Extract from ML result#
e_val = res$output@params_table["e","est"] # Extract from ML result#
j_val = res$output@params_table["j","est"]#
########################################################
# Set up an equivalent ClaSSE model in diversitree#
########################################################
#
# This .R file contains a bunch of extract functions that diversitree#
# uses behind the scenes. They are very hard to access normally, #
# because diversitree does tons of "functions writing other functions".#
source('/GitHub/BioGeoJulia.jl/Rsrc/ClaSSE_mods_v2.R', chdir = TRUE)#
#
# Convert the BioGeoBEARS cladogenesis matrix into a data.frame#
# This handily shows the #
# * per-event weights (column "wt") and #
# * per-event probabilities (column "prob")#
include_null_range = res$inputs$include_null_range#
Carray_df = get_Cevent_probs_df_from_mats(mats, include_null_range=include_null_range)#
head(Carray_df)#
tail(Carray_df)#
#
# Set up a ClaSSE model from diversitree#
#
# Get the tip statenums#
numtips = length(tr$tip.label)#
numstates = ncol(res$relative_probs_of_each_state_at_branch_top_AT_node_DOWNPASS)#
tip_statenums = rep(0, times=numtips)#
for (i in 1:numtips)#
	{ # Find the "1" (the observed state for each tip)#
	TF = res$relative_probs_of_each_state_at_branch_top_AT_node_DOWNPASS[i,] == 1#
	tip_statenums[i] = (1:numstates)[TF]#
	}#
tip_statenums#
names(tip_statenums) = tr$tip.label#
states = tip_statenums#
#
# Set the sampling rate to 1 for each state#
sampling.f = rep(1, times=numstates)#
k = numstates#
#
# Create the ClaSSE likelihood function for k states#
# (strict=FALSE means that some states in the state space can be absent from the tips)#
classe_Kstates = make.classe(tree=tr, states=states, k=k, sampling.f=sampling.f, strict=FALSE)#
#
# The names of the ClaSSE parameters:#
# Note that diverstree creates ALL the possible parameters, which gets#
# ridiculous quickly, e.g. #
# 4 areas = 16 geographic range states = 2432 parameters in param_names#
param_names = argnames(classe_Kstates)#
length(param_names)#
length(param_names[grepl(pattern="lambda", x=param_names)]) # 2176 speciation rates#
length(param_names[grepl(pattern="mu", x=param_names)])     #   16 extinction rates#
length(param_names[grepl(pattern="q", x=param_names)])      #  240 Q transition rates#
#
# Most parameters will be zero#
classe_params = rep(0, times=length(param_names))#
names(classe_params) = param_names#
head(classe_params)#
tail(classe_params)#
#
# Make a data.frame to match up with the BioGeoBEARS Carray_df#
lambda_ijk_df = classe_lambdas_to_df(classe_params, k=numstates)#
head(lambda_ijk_df)#
#
# Fill in the params from the BioGeoBEARS "res" results#
classe_params = BGBres_into_classe_params(res, classe_params, birthRate=birthRate)#
classe_params[153]#
classe_params["lambda020202"]#
classe_params["lambda060203"]#
classe_params["q0206"]#
classe_params["q1516"]#
classe_params[classe_params != 0.0]#
#
# Set up various assumptions about the root state probabilities#
# All probabilities equal, except null range has prob=0#
root_probs_equal = rep(1, times=numstates)#
root_probs_equal[sum(include_null_range)] = 0#
root_probs_equal = root_probs_equal / sum(root_probs_equal)#
#
# Highly biased towards the last state#
root_probs_biased = rep(0.01, times=numstates)#
root_probs_biased[sum(include_null_range)] = 0#
root_probs_biased[length(root_probs_biased)] = 0.01 * (numstates-include_null_range)#
root_probs_biased = root_probs_biased / sum(root_probs_biased)#
#
# All states, except null range, get "probability" 1#
# (i.e., ignore root state frequencies, like DEC-type models)#
root_probs_single = rep(1, times=numstates)#
root_probs_single[sum(include_null_range)] = 0#
#
# Do the ClaSSE calculation, under these different assumptions#
res1 = classe_Kstates(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
res2 = classe_Kstates(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
root_probs = root_probs_equal#
res3 = classe_Kstates(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = root_probs_biased#
res4 = classe_Kstates(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
root_probs = root_probs_single#
res5 = classe_Kstates(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=FALSE)#
res6 = classe_Kstates(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=FALSE)#
#
res1t = classe_Kstates(pars=classe_params, root=ROOT.OBS, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
res2t = classe_Kstates(pars=classe_params, root=ROOT.FLAT, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
root_probs = root_probs_equal#
res3t = classe_Kstates(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = root_probs_biased#
res4t = classe_Kstates(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
root_probs = root_probs_single#
res5t = classe_Kstates(pars=classe_params, root=ROOT.GIVEN, root.p=root_probs, intermediates=TRUE, condition.surv=TRUE)#
res6t = classe_Kstates(pars=classe_params, root=ROOT.EQUI, root.p=NULL, intermediates=TRUE, condition.surv=TRUE)#
#
# get_classe_LnLs returns the total log-likelihood, and #
# the total of the branch likelihoods#
LnLs1 = get_classe_LnLs(res1)#
LnLs2 = get_classe_LnLs(res2)#
LnLs3 = get_classe_LnLs(res3)#
LnLs4 = get_classe_LnLs(res4)#
LnLs5 = get_classe_LnLs(res5)#
LnLs6 = get_classe_LnLs(res6)#
LnLs1t = get_classe_LnLs(res1t)#
LnLs2t = get_classe_LnLs(res2t)#
LnLs3t = get_classe_LnLs(res3t)#
LnLs4t = get_classe_LnLs(res4t)#
LnLs5t = get_classe_LnLs(res5t)#
LnLs6t = get_classe_LnLs(res6t)#
#
LnLst = as.data.frame(rbind(LnLs1, LnLs2, LnLs3, LnLs4, LnLs5, LnLs6, LnLs1t, LnLs2t, LnLs3t, LnLs4t, LnLs5t, LnLs6t), stringsAsFactors=FALSE)#
names(LnLst) = c("ttl_LnL", "branch_LnL")#
ObsDiff = (LnLst$ttl_LnL - LnLst$branch_LnL)#
exp_ObsDiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL))#
LnLdiff = round((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)), digits=4)#
exp_LnLdiff = exp((LnLst$ttl_LnL - LnLst$branch_LnL - log(birthRate)))#
LnLst2 = cbind(LnLst, ObsDiff, LnLdiff, exp_ObsDiff, exp_LnLdiff)#
#
# Put the total and branch lnLs in a table; other columns were experimenting#
# with various assumptions about constants (ignore except in ultra-simple cases)#
all_lnLs = cft(LnLst2, numdigits_inbetween_have_fixed_digits=8)#
all_lnLs$ttl_LnL = as.numeric(all_lnLs$ttl_LnL)#
all_lnLs$branch_LnL = as.numeric(all_lnLs$branch_LnL)#
all_lnLs$ObsDiff = as.numeric(all_lnLs$ObsDiff)#
all_lnLs$LnLdiff = as.numeric(all_lnLs$LnLdiff)#
all_lnLs$exp_ObsDiff = as.numeric(all_lnLs$exp_ObsDiff)#
all_lnLs$exp_LnLdiff = as.numeric(all_lnLs$exp_LnLdiff)#
all_lnLs
init = t(attr(res2, "intermediates")$init)#
init#
#
base = t(attr(res2, "intermediates")$base)#
base
Ds_cols = (numstates+1):(2*numstates)#
lq = t(attr(res2, "intermediates")$lq)#
lq#
rowSums(base[,Ds_cols])#
base[,Ds_cols] * exp(c(lq))#
rowSums(base[,Ds_cols] * exp(c(lq)))#
log(rowSums(base[,Ds_cols] * exp(c(lq))))#
#
# Store the likelihoods at branch-bottoms for comparison#
base_likes = apply(X=base[,Ds_cols], MARGIN=2, FUN="*", exp(lq))#
base_normlikes = base_likes / rowSums(base_likes)#
#
# Diversitree normalized likelihoods at branch bottoms match BioGeoBEARS#
round(base_normlikes - res$relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS, 5)#
#
# These match the lqs, but this is because base_likes = base_normlikes * exp(lq)#
tmp_rowSums = (base_likes / res$relative_probs_of_each_state_at_branch_bottom_below_node_DOWNPASS)[,numstates]#
tmp_rowSums#
log(tmp_rowSums)#
sum(log(tmp_rowSums), na.rm=TRUE) # matches sum(lq)#
sum(lq)#
log(tmp_rowSums) - attr(res4,"intermediates")$lq#
# Diversitree birthdeath calculation#
lik.bd <- make.bd(tree=tr, sampling.f=NULL, unresolved=NULL, times=NULL, control=list(method="ode"))#
diversitree_bd = lik.bd(pars=c(birthRate=birthRate, deathRate=deathRate), intermediates=TRUE)#
c(diversitree_bd)    # log-likelihood = 0.4870967#
yule(tr)$loglik      # log-likelihood = 0.4870968#
#
# Likelihood equation in the birthdeath function#
# (derived by pulling apart the birthdeath() function from ape)#
# This version stores all of the piece, for comparison#
# bd_ape$lnL = 0.4870968#
bd_ape = bd_liks(tr, birthRate=birthRate, deathRate=deathRate)#
bd_ape#
#
# Note how this equals -(tr$Nnode-1)#
bd_ape$lnl_Births_above_root + bd_ape$lnl_branching_times#
-(tr$Nnode-1)#
#
# The diversitree birth-death function also stores #
# branch-bottom likelihoods in "lq"#
bd_lq = attr(diversitree_bd,"intermediates")$lq#
sum(bd_lq)#
sum(bd_lq) - -(tr$Nnode-1)#
bd_ape$lnl_numBirths#
#
# Compare bd_lq and -birthRate * trtable$edge.length#
trtable = prt(tr, printflag=FALSE) # prints the tree to node-order table#
bd_lq#
-birthRate * trtable$edge.length#
#
# Differences#
round(bd_lq - (-birthRate * trtable$edge.length), digits=4)#
#
# What is that -1.1123?#
log(birthRate) # i.e., a log(birthRate) for every internal node
root_nodenum = length(tr$tip.label) + 1#
sumBGBlike_not_root = sum(log(res$computed_likelihoods_at_each_node[-root_nodenum]))#
sumBGBlike_not_root#
#
# Let's take the sum of the branch-bottom likelihoods from the birth-death#
# process#
sum(bd_lq)#
bd_ape$lnl_numBirths + bd_ape$lnl_Births_above_root + bd_ape$lnl_branching_times#
bd_ape$lnl_numBirths + -(tr$Nnode-1)#
sum(-birthRate * trtable$edge.length, na.rm=TRUE) + (tr$Nnode-1)*log(birthRate) #
sum_branchBot_likes = sum(-birthRate * trtable$edge.length, na.rm=TRUE) + (tr$Nnode-1)*log(birthRate) #
#
# Add the lnL of root speciation event, -1 for extra node#
all_lnLs#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1)#
sumBGBlike_not_root + sum_branchBot_likes + -log(1/birthRate) + 1#
#
# Matches!#
#
# We can also add the root state likelihoods, if desired#
BGBlnL_at_root = log(res$computed_likelihoods_at_each_node[root_nodenum]) - 1#
d_root_orig_BGB = res$relative_probs_of_each_state_at_branch_top_AT_node_DOWNPASS[root_nodenum,] * exp(BGBlnL_at_root)#
d_root_orig_BGB#
sum(d_root_orig_BGB)#
#
vals = t(attr(res1, "intermediates")$vals)	# Es and Ds at the root#
E_indices = 1:numstates#
d_root_orig_diversitree = vals[-E_indices]#
d_root_orig_diversitree#
sum(d_root_orig_diversitree)#
#
# Match BioGeoBEARS to diverstree res1#
root.p = d_root_orig/sum(d_root_orig)#
rootlikes = log(sum(root.p * d_root_orig))#
rootlikes#
#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1) + rootlikes#
c(res1)
# Match BioGeoBEARS to diverstree res1#
root.p = d_root_orig_BGB/sum(d_root_orig_BGB)#
rootlikes = log(sum(root.p * d_root_orig_BGB))#
rootlikes#
#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1) + rootlikes#
c(res1)
root.p = rep(1/numstates, times=nstates)#
rootlikes = log(sum(root.p * d_root_orig))#
rootlikes#
#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1) + rootlikes#
c(res2)
# Match BioGeoBEARS to diverstree res2#
root.p = rep(1/numstates, times=nstates)#
rootlikes = log(sum(root.p * d_root_orig_BGB))#
rootlikes#
#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1) + rootlikes#
c(res2)#
#
# Match BioGeoBEARS to diverstree res3 (all equal, except null range)#
# Set up various assumptions about the root state probabilities#
# All probabilities equal, except null range has prob=0#
root_probs_equal = rep(1, times=numstates)#
root_probs_equal[sum(include_null_range)] = 0#
root_probs_equal = root_probs_equal / sum(root_probs_equal)#
root.p = root_probs_equal#
rootlikes = log(sum(root.p * d_root_orig_BGB))#
rootlikes#
#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1) + rootlikes#
c(res3)
root_probs_single = rep(1, times=numstates)#
root_probs_single[sum(include_null_range)] = 0#
root.p = root_probs_single#
rootlikes = log(sum(root.p * d_root_orig))#
rootlikes#
#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1) + rootlikes#
c(res5)
root_probs_single = rep(1, times=numstates)#
root_probs_single[sum(include_null_range)] = 0#
root.p = root_probs_single#
rootlikes = log(sum(root.p * d_root_orig_BGB))#
rootlikes#
#
sumBGBlike_not_root + sum_branchBot_likes - (log(1/birthRate) - 1) + rootlikes#
c(res5)
cache <- diversitree:::make.cache.bd(tree=tr, sampling.f=NULL, unresolved=NULL, times=NULL, control=list(method="ode"))#
cache$const             # 36.39545#
bd_ape$lnl_topology     # 36.39545#
lfactorial(tr$Nnode)    # 36.39545
base = t(attr(res2, "intermediates")$base)#
base#
lq = t(attr(res2, "intermediates")$lq)#
lq#
all_lnLs#
R_result_branch_lnL = sum(lq)#
R_result_total_LnLs1 = c(res1)#
R_result_total_LnLs1t = c(res1t)#
#
# Does the total of branch likelihoods (lq) + node likelihoods match R?#
computed_likelihoods_at_each_node_x_lambda = rep(0.0, times=tr$Nnode + length(tr$tip.label))#
#
computed_likelihoods_at_each_node_just_before_speciation = get_sum_log_computed_likes_at_each_node(tr, base, lq, classe_params)#
computed_likelihoods_at_each_node_just_before_speciation#
rowSums(computed_likelihoods_at_each_node_just_before_speciation)#
log(rowSums(computed_likelihoods_at_each_node_just_before_speciation))#
TF = is.finite(log(rowSums(computed_likelihoods_at_each_node_just_before_speciation)))#
sum(log(rowSums(computed_likelihoods_at_each_node_just_before_speciation)[TF]))#
R_result_sum_log_computed_likelihoods_at_each_node = sum(log(rowSums(computed_likelihoods_at_each_node_just_before_speciation)[TF]))
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = R_result_sum_log_computed_likelihoods_at_each_node + sum(lq)#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
R_result_branch_lnL = sum(lq)#
R_result_total_LnLs1 = c(res1)#
R_result_total_LnLs1t = c(res1t)
R_result_branch_lnL
R_result_total_LnLs1
R_result_total_LnLs1t
DEC_R_result_branch_lnL = -67.6295#
DEC_R_result_total_LnLs1 = -72.60212#
DEC_R_result_total_LnLs1t = -57.72533#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -120.1545#
#
# DEC+J#
R_result_branch_lnL = -55.37332#
R_result_total_LnLs1 = -58.83758#
R_result_total_LnLs1t = -71.48986#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -96.34151#
DEC_R_result_branch_lnL - R_result_branch_lnL
DEC_R_result_branch_lnL = -67.6295#
DEC_R_result_total_LnLs1 = -72.60212#
DEC_R_result_total_LnLs1t = -57.72533#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -120.1545#
#
# DEC+J#
R_result_branch_lnL = -55.37332#
R_result_total_LnLs1 = -58.83758#
R_result_total_LnLs1t = -71.48986#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -96.34151#
DEC_R_result_branch_lnL - R_result_branch_lnL#
DEC_R_result_total_LnLs1 - R_result_total_LnLs1#
DEC_R_result_total_LnLs1t - R_result_total_LnLs1t#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda - R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
base = t(attr(res2, "intermediates")$base)#
base#
lq = t(attr(res2, "intermediates")$lq)#
lq#
all_lnLs#
R_result_branch_lnL = sum(lq)#
R_result_total_LnLs1 = c(res1)#
R_result_total_LnLs1t = c(res1t)
R_result_branch_lnL
.34.5*.20.9
-34.5--20.9
c(res1)
c(res1t)
DEC_R_result_branch_lnL = -67.6295#
DEC_R_result_total_LnLs1 = -72.60212#
DEC_R_result_total_LnLs1t = -57.72533#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -120.1545#
#
# DEC+J#
R_result_branch_lnL = -55.37332#
R_result_total_LnLs1 = -58.83758#
R_result_total_LnLs1t = -57.72533#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -96.34151#
-34.5--20.9#
DEC_R_result_branch_lnL - R_result_branch_lnL#
DEC_R_result_total_LnLs1 - R_result_total_LnLs1#
DEC_R_result_total_LnLs1t - R_result_total_LnLs1t#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda - R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
c(res1t)
DEC_R_result_branch_lnL = -67.6295#
DEC_R_result_total_LnLs1 = -72.60212#
DEC_R_result_total_LnLs1t = -71.48986#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -120.1545#
#
# DEC+J#
R_result_branch_lnL = -55.37332#
R_result_total_LnLs1 = -58.83758#
R_result_total_LnLs1t = -57.72533#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -96.34151#
-34.5--20.9#
DEC_R_result_branch_lnL - R_result_branch_lnL#
DEC_R_result_total_LnLs1 - R_result_total_LnLs1#
DEC_R_result_total_LnLs1t - R_result_total_LnLs1t#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda - R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
res
res
DEC_lnL = -34.54313#
DEC_R_result_branch_lnL = -67.6295#
DEC_R_result_total_LnLs1 = -72.60212#
DEC_R_result_total_LnLs1t = -71.48986#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -120.1545#
#
# DEC+J#
DECj_lnL = -20.94759#
R_result_branch_lnL = -55.37332#
R_result_total_LnLs1 = -58.83758#
R_result_total_LnLs1t = -57.72533#
R_result_sum_log_computed_likelihoods_at_each_node_x_lambda = -96.34151#
DEC_lnL - DECj_lnL#
DEC_R_result_branch_lnL - R_result_branch_lnL#
DEC_R_result_total_LnLs1 - R_result_total_LnLs1#
DEC_R_result_total_LnLs1t - R_result_total_LnLs1t#
DEC_R_result_sum_log_computed_likelihoods_at_each_node_x_lambda - R_result_sum_log_computed_likelihoods_at_each_node_x_lambda
sum(lq)
j
res
